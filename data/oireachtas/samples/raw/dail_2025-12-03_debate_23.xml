<akomaNtoso xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://docs.oasis-open.org/legaldocml/ns/akn/3.0/CSD13" xsi:schemaLocation="http://docs.oasis-open.org/legaldocml/ns/akn/3.0/CSD13 ./akomantoso30.xsd">
  <debate name="Official Report">
    <meta>
      <identification source="#debates">
        <FRBRWork>
          <FRBRthis value="/akn/ie/debateRecord/joint_committee_on_arts_media_communications_culture_and_sport/2025-12-03/debate/main"/>
          <FRBRuri value="/akn/ie/debateRecord/joint_committee_on_arts_media_communications_culture_and_sport/2025-12-03/debate"/>
          <FRBRdate date="2025-12-03" name="#generation"/>
          <FRBRauthor as="#author" href="/ie/oireachtas/committee/dail/34/joint_committee_on_arts_media_communications_culture_and_sport"/>
          <FRBRcountry value="ie"/>
          <FRBRname value="debate"/>
        </FRBRWork>
        <FRBRExpression>
          <FRBRthis value="/akn/ie/debateRecord/joint_committee_on_arts_media_communications_culture_and_sport/2025-12-03/debate/mul@/main"/>
          <FRBRuri value="/akn/ie/debateRecord/joint_committee_on_arts_media_communications_culture_and_sport/2025-12-03/debate/mul@"/>
          <FRBRdate date="2025-12-03" name="#reported"/>
          <FRBRauthor as="#editor" href="#debates"/>
          <FRBRlanguage language="eng"/>
        </FRBRExpression>
        <FRBRManifestation>
          <FRBRthis value="/akn/ie/debateRecord/joint_committee_on_arts_media_communications_culture_and_sport/2025-12-03/debate/mul@/main.xml"/>
          <FRBRuri value="/akn/ie/debateRecord/joint_committee_on_arts_media_communications_culture_and_sport/2025-12-03/debate/mul@.akn"/>
          <FRBRdate date="2025-12-10" name="#publication"/>
          <FRBRauthor as="#editor" href="#debates"/>
        </FRBRManifestation>
      </identification>
      <references source="#debates">
        <TLCPerson eId="AlanKelly" href="/ie/oireachtas/member/id/Alan-Kelly.S.2007-07-23" showAs="Alan Kelly"/>
        <TLCPerson eId="AlisonComyn" href="/ie/oireachtas/member/id/Alison-Comyn.S.2025-01-29" showAs="Alison Comyn"/>
        <TLCPerson eId="EvanneNiChuilinn" href="/ie/oireachtas/member/id/Evanne-Ní-Chuilinn.S.2025-01-29" showAs="Evanne Ní Chuilinn"/>
        <TLCPerson eId="JoannaByrne" href="/ie/oireachtas/member/id/Joanna-Byrne.D.2024-11-29" showAs="Joanna Byrne"/>
        <TLCPerson eId="MalcolmNoonan" href="/ie/oireachtas/member/id/Malcolm-Noonan.D.2020-02-08" showAs="Malcolm Noonan"/>
        <TLCPerson eId="SineadGibney" href="/ie/oireachtas/member/id/Sinéad-Gibney.D.2024-11-29" showAs="Sinéad Gibney"/>
        <TLCRole href="role/chair" showAs="Chair" eId="Chair"/>
        <TLCRole href="role/vice_chairman" showAs="Vice Chairman" eId="Vice_Chairman"/>
        <TLCRole href="role/author" showAs="author" eId="author"/>
        <TLCRole href="role/editor" showAs="editor" eId="editor"/>
      </references>
    </meta>
    <preface>
      <block name="title_ga">
        <docTitle>DÍOSPÓIREACHTAÍ PARLAIMINTE</docTitle>
      </block>
      <block name="title_en">
        <docTitle>PARLIAMENTARY DEBATES</docTitle>
      </block>
      <block name="proponent_ga">
        <docProponent>TITHE an OIREACHTAS</docProponent>
      </block>
      <block name="proponent_en">
        <docProponent>HOUSES OF THE OIREACHTAS</docProponent>
      </block>
      <block name="committee_ga">
        <docCommittee>AN COMHCHOISTE UM EALAÍONA, MEÁIN, CUMARSÁID, CULTÚR AGUS SPÓRT</docCommittee>
      </block>
      <block name="committee_en">
        <docCommittee>Joint Committee on Arts, Media, Communications, Culture and Sport</docCommittee>
      </block>
      <block name="status_ga">
        <docStatus>TUAIRISC OIFIGIÚIL</docStatus>
      </block>
      <block name="status_en">
        <docStatus>(OFFICIAL REPORT)</docStatus>
      </block>
      <block name="date_ga">
        <docDate date="2025-12-03">Dé Céadaoin, 03 Nollaig 2025</docDate>
      </block>
      <block name="date_en">
        <docDate date="2025-12-03">Wednesday, 03 December 2025</docDate>
      </block>
      <block refersTo="#unrevised" name="version_en">
        <docStatus/>
      </block>
      <block refersTo="#unrevised" name="version_ga">
        <docStatus/>
      </block>
    </preface>
    <debateBody>
      <debateSection name="prelude" eId="dbsect_1">
        <summary class="Center" eId="sum_1">Tháinig an Comhchoiste le chéile ag 12:30 p.m.</summary>
        <summary class="Center" eId="sum_2">The Joint Committee met at 12:30 p.m.</summary>
        <rollCall>
          <summary class="Center" eId="sum_3">Comhaltaí a bhí i láthair / Members present:</summary>
          <table>
            <tr>
              <th>
                <p eId="para_1">Teachtaí Dála / Deputies</p>
              </th>
              <th>
                <p eId="para_2">Seanadóirí / Senators</p>
              </th>
            </tr>
            <tr>
              <td>
                <p eId="para_3">
                  <person refersTo="#JoannaByrne">Joanna Byrne</person>
                </p>
              </td>
              <td>
                <p eId="para_4">
                  <person refersTo="#AlisonComyn">Alison Comyn</person>
                </p>
              </td>
            </tr>
            <tr>
              <td>
                <p eId="para_5">
                  <person refersTo="#SineadGibney">Sinéad Gibney.</person>
                </p>
              </td>
              <td>
                <p eId="para_6">
                  <person refersTo="#EvanneNiChuilinn">Evanne Ní Chuilinn</person>
                </p>
              </td>
            </tr>
            <tr>
              <td/>
              <td>
                <p eId="para_7">
                  <person refersTo="#MalcolmNoonan">Malcolm Noonan.</person>
                </p>
              </td>
            </tr>
          </table>
          <summary eId="sum_4">
            <person as="#Chair" refersTo="#AlanKelly">Teachta / Deputy Alan Kelly sa Chathaoir / in the Chair.</person>
          </summary>
        </rollCall>
      </debateSection>
      <debateSection name="debate" eId="dbsect_2">
        <heading>Regulation of Online Platforms and Supports to Improve Online Safety and Participation: Discussion (Resumed)<recordedTime time="2025-12-03T12:30:00+00:00"/></heading>
        <speech by="#AlanKelly" eId="spk_1">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T12:30:00+00:00"/></from>
          <p eId="para_8">We have apologies from Deputies Carrigy, Brennan and Byrne. Today's meeting has been convened to continue the committee's scrutiny of matters related to the regulation of online platforms and supports to improve online safety and participation.</p>
          <p eId="para_9"> I welcome from CyberSafeKids Ms Alex Cooney, co-founder and CEO, and Ms Martina Walsh, policy analyst; and from the Children's Rights Alliance Ms. Noeline Blackwell, online safety co-ordinator, and Ms Alex Murphy, online safety legal officer.</p>
          <p eId="para_10"> The format of today's meeting is that I will invite the witnesses to deliver an opening statement, which is limited to five minutes. The statements will then be followed by questions from members of the committee. As the witnesses are probably aware, the committee will publish the opening statements online. Is that agreed? Agreed.</p>
          <p eId="para_11"> Before we move to today's discussion, I wish to clarify some limitations in relation to parliamentary privilege and the practices of the Houses as regards references witnesses may make to other persons in their evidence. The evidence of witnesses physically present or who give evidence from within the parliamentary precincts is protected pursuant to both the Constitution and statute by absolute privilege in respect of presentations they make to the committee. This means they have an absolute defence against any defamation action for anything they say at the meeting. However, they are expected not to abuse this privilege and it is my duty as Chair to ensure that this privilege is not abused. Therefore, if their statements are potentially defamatory in relation to an identifiable person or entity, they will be directed to discontinue their remarks. It is imperative that they comply with any such direction.</p>
          <p eId="para_12"> Members are reminded of the long-standing parliamentary practice to the effect that they should not comment on, criticise or make charges against a person outside the Houses or any official either by name or in such a way as to make him or her identifiable. Is that agreed? Agreed.</p>
          <p eId="para_13"> I invite Ms Cooney to make her opening statement on behalf of CyberSafeKids.</p>
        </speech>
        <speech by="#" eId="spk_2">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T12:30:00+00:00"/></from>
          <p eId="para_14">I thank the Chair, and members of the committee, for inviting us here today. I am CEO and co-founder of CyberSafeKids, and I am joined by my colleague Martina Walsh. We will keep our remarks brief and are very happy to take questions.</p>
          <p eId="para_15"> CyberSafeKids is an Irish charity established ten years ago to build a safer digital world for children. In that time, we have spoken to almost 100,000 children in schools across the country and thousands of parents, teachers, social workers, foster carers, youth workers and law enforcement professionals. We also work closely with policymakers and industry. Our decade of research into children’s digital lives underpins all of our education, advocacy and policy work.</p>
          <p eId="para_16"> We would like to frame our remarks today in the context of the UN Convention on the Rights of the Child, in particular general comment No. 25, which sets out children’s rights in the digital environment. These include the right to participate, the right to be protected from harm, the right not to be exploited for commercial gain and the right to access true and accurate information. In practice, however, children are routinely failed in respect of these rights every time they go online.</p>
          <p eId="para_17"> The committee has asked us to speak about regulation and to what extent it will improve online safety for children. I will give a brief overview of what is now in place and then highlight the gaps that require urgent attention. At a national level, the Online Safety and Media Regulation Act 2022 established Coimisiún na Meán and Ireland’s online safety framework. The first online safety code, OSC, places binding obligations on video-sharing platforms headquartered in the State, including YouTube, Meta, TikTok and so on.</p>
          <p eId="para_18"> At European level, the Digital Services Act, DSA, is key. Article 28 focuses specifically on protecting minors, using a risk management and proportionate to size approach. Ireland plays a central supervisory role because so many of the EU’s very large online platforms, VLOPS, are based here. The Commission has also issued guidelines to help interpret Article 28 which set out important but non-binding expectations for child safety.</p>
          <p eId="para_19"> On AI, the AI Act represents another important step, but is already struggling to keep pace with reality. It was drafted before the rapid mainstream adoption of generative AI tools and conversational chatbots, technologies that children are engaging with daily. Unlike every toy intended for children, which is subject to rigorous risk and compliance testing, these addictive technologies are rolled out from one day to the next into the hands of vulnerable children without any such checks and balances.</p>
          <p eId="para_20"> On gaps and concerns, we are still at the early stages of enforcing these new regulations and it will take time to see how they will affect children in Ireland and across Europe, but we already see several challenges ahead, which I will briefly outline. First, our national legislation applies only to those entities based in the State, so does not apply to popular environments that children use like Snapchat and Roblox. We still lack a coherent plan for age-gating adult content, in contrast to several other European countries. We lack clarity and timelines regarding an individual complaints mechanism and there are no mandated timelines around complaints handling laid out in the online safety code. Ireland may need to amend the Online Safety and Media Regulation Act to allow for enforceable minimum age requirements. Coimisiún na Meán lacks adequate information-gathering powers and must open a formal investigation to compel the provision of information. At European level, the heavy focus on very large platforms overlooks some of the digital spaces children use most, particularly gaming platforms like Roblox, which is the most popular online environment for under-13s in Ireland. It also overlooks adult content sites with fewer than 45 million users, which are entirely accessible to children. Enforcement timelines remain uncertain and the regulatory system relies on platforms’ self-assessment of risk. In other words, there is no independent assessment of risk against an agreed framework. Enforcement will be challenging since language in the Article 28 guidelines is unclear and leaves far too much to the discretion of the company. For example, in relation to recommender systems, they talk about "prioritising" explicit user signals over implicit signals, which would be based on profiling, but how do you interpret whether they have prioritised?</p>
          <p eId="para_21"> The AI Act does not adequately address the unique risks AI systems pose to minors, including hyper-personalised influence, emotional manipulation and the blurring of boundaries between automated agents and real people. In short, the regulatory framework for AI, as for social media, is reactive and does not mandate safety by design. As such, it is already outdated and children are interacting with systems the law does not yet properly recognise or regulate. A crucial point is that GenAI chatbots are not categorised as high-risk in relation to children, when in our view they must be. In the last few days we have heard there will be delays to implementation and likely a watering-down of the regulation.</p>
          <p eId="para_22"> On industry responsiveness, time and time again the industry seems to prioritise its commercial interests over the protection of minors, resulting in half-hearted window-dressing efforts to reduce online risk. Its commitment to online safety has to be questioned, considering Meta’s troubling decision to end third-party fact-checking in January 2025 and scale back content moderation. Despite issuing fines totalling almost €4 billion, Ireland’s Data Protection Commission has recouped only 0.6% of that amount to date. This raises fundamental questions about deterrence and compliance. There has also been increased, co-ordinated lobbying by big tech and the White House to restrict Europe’s ability to regulate within its own jurisdiction.</p>
          <p eId="para_23"> Our recommendations include implementation of the use of mandatory age verification solutions at a national level for all digital environments, to all content that impairs, per the Digital Services Act, the "physical, mental and moral development" of a minor, regardless of where the provider is domiciled. This could be imposed via a national mechanism or a harmonised EU approach, but it must be done with urgency so every child in Ireland is better protected from harmful and dangerous content. We recommend the implementation of an independent risk classification system for all digital environments, not just the very large ones, conducted by a national body or independent third party to categorise the risks to minors and determine in what situations age verification is required. This could start on a national basis, ideally leading to a European-wide framework. Non-compliant digital products and services should be subject to geoblocking. Recommender systems must be based on explicit user signals only and must not recommend any content that impairs the physical, mental or moral development of a minor. Addictive design features must be disabled by default for minors. We must embed critical digital literacy education across the curriculum, including upskilling teachers. We should consider the Finnish model, which has taken a cradle to grave approach since 2014 regarding upskilling their citizens. We should enforce personal liability for senior executives of relevant technology companies, as applies in other sectors with wide-ranging societal impacts. We should strengthen the Online Safety and Media Regulation Act to give Coimisiún na Meán greater information-gathering powers and resources to empower it to properly enforce the regulation. This should include prescriptive timeframes for the handling of complaints and an individual complaints mechanism. I thank members for their attention.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_3">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T12:40:00+00:00"/></from>
          <p eId="para_24">I thank Ms Cooney and invite Ms Blackwell to give her statement.</p>
        </speech>
        <speech by="#" eId="spk_4">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T12:40:00+00:00"/></from>
          <p eId="para_25">I thank the Chair and the committee for inviting us to contribute to their deliberations. The Children's Rights Alliance is an organisation uniting over 160 organisations around Ireland working on children's rights and welfare.</p>
          <p eId="para_26"> The committee's focus on the regulation of online platforms is very timely in this digital age for all of us and especially for children and those who care for them, including their parents, educators and other carers. Over the past 30 years the Internet has been the basis for the development of a massive industry where online platforms, including social media companies, all kinds of apps, communications channels and online shopping sites have all made fortunes, or lost them. Frankly, that growth happened while the law looked on, largely at a loss as to how it might legitimately engage with this apparently virtual world in the interests of citizens and residents of states. It is really only in the last decade that solid progress is being made in recognising that this virtual world brings real consequences not just for the massive tech industry, but also for those who engage with it.</p>
          <p eId="para_27"> Looking at the Irish landscape, the last four or five years have brought about the first real attempt to define those responsibilities and to regulate the companies to live up to them. Ireland has to be commended for taking significant steps in the past four years through legislation and the appointment of a regulator. This has mostly been done in conjunction with European Union-wide legislation. However, the system of regulation that has been brought into place, namely, principles-based regulation, is awkward in many ways because while it sets goals for various online platforms it gives them - as my friend Ms Cooney from CyberSafeKids, which is a member of the Children's Rights Alliance, has said - discretion in how they achieve these objectives. The advantage of that is it is flexible and can be applied across EU jurisdictions. The disadvantage is not only that companies must have time to implement solutions, but that each company can adopt its own solution, which makes it difficult for users to understand all the various structures on various platforms. For example, the absence of standardised and transparent reporting and complaints mechanisms is confusing to users and denies them access to justice. The committee heard from the regulator last week. In using its supervisory authority and investigative powers, of necessity it has to operate painfully slowly when seen from the perspective of a child who is at risk from harmful systems or content.</p>
          <p eId="para_28"> In the briefing paper we have circulated to the committee, we highlight issues of concern in the regulation of platforms and supports to improve online safety and participation. We note that above all, many of the issues that give problems and concern today would be solved if the tech industry had to make sure all of their products and systems promoted and promulgated throughout the EU are safe by design and default. There is a big distance to go before that happens for tech, although it is now the norm for many physical products and systems, from baby formula to cars. It is also increasingly clear that this is unlikely to be done on a voluntary basis by the tech companies and it is only likely to happen with firm regulation. In the briefing paper we also address the need for platforms to be clear about who is a child and who therefore is entitled to protection as a child from adult and violent content. This involves effective, privacy-preserving age assurance mechanisms that are still only in development.</p>
          <p eId="para_29"> In the context of age assurance and also of the horrors and crimes of child sexual abuse and exploitation, we note the unfortunate polarisation that has taken place between human rights activists where the singular focus on the right to privacy has impeded progress on children's right to protection from cruel, inhumane and degrading treatment. We say that dichotomy is false, but that the issues need to be better ventilated in a balanced way. We suggest the upcoming Irish Presidency of the EU Council could include priority actions on this. It could also advance in a very child rights-friendly way a long-overdue regulation on child sexual abuse material. The Government has been a steadfast advocate at EU level for progress on this.</p>
          <p eId="para_30">It is to be hoped that in 2026, it will use its agenda and priority setting powers to ensure the most robust protection possible in what is, frankly, quite a weakened regulation.</p>
          <p eId="para_31"> There is little discussion happening in this committee at the moment or elsewhere, about the independent complaints mechanism. Whatever regulation is in place can only work if there is such a mechanism. For child users and their parents, there should be child-friendly, accessible systems to allow children to easily report harmful content and unwanted contact. Apart from that, there is an obligation under the Online Safety and Media Regulation Act of 2022 to provide an individual complaints mechanism to the online safety commissioner. That structure is not yet in place, and therefore children lack a binding accountability mechanism that is needed. Our briefing refers to the enhanced harms that can happen through AI-infused recommender systems, AI chatbots and discriminatory patterns that create bias and risks to privacy. All of these require further scrutiny under the EU AI Act, which notes the vulnerability of children but fails to sufficiently identify how they are at risk.</p>
          <p eId="para_32"> Finally, all regulation, law and policy with digital implications needs a simple technique: the review of all law and policy through a child-rights impact assessment. We recommend that Ireland adopts this in all its laws and policies, and that where online safety and child rights are in play, these also be included in our national digital strategies, which they are not in the current version. All manner of child rights need to be protected, namely, the right not to be discriminated against, for children to have their best interests taken into account in matters concerning them, their right to life, survival and development, and their right for their own views to be heard and considered in matters affecting them. I thank the committee. We are open to questions. </p>
        </speech>
        <speech by="#AlanKelly" eId="spk_5">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T12:50:00+00:00"/></from>
          <p eId="para_33">I thank Ms Blackwell. We are open to questions now, and first is Senator Ní Chuilinn. </p>
        </speech>
        <speech by="#EvanneNiChuilinn" eId="spk_6">
          <from>Senator Evanne Ní Chuilinn<recordedTime time="2025-12-03T12:50:00+00:00"/></from>
          <p eId="para_34">I thank all of the witnesses for coming in and for their very comprehensive opening statements. There were a couple of issues both witnesses mentioned around recommender systems and age verification. Those are two of the key protective measures that we should be, and are, discussing. We had a discussion with Coimisún na Meán about them last week.</p>
          <p eId="para_35"> I ask both of the witnesses for their views on recommender systems. Do they believe that there is any way that we can legislate, either here or at European level, to have some form of a ban for younger people? Then we are into age verification and how to prove somebody is a certain age. At the moment, some of the sites a person can go on, including pornography sites, ask "Are you over or under 18?" That is not age verification. How do the witnesses see that working? Could the Government instil this in that we could use <i>mygov.ie , </i>for example, and if people have a phone, they have to have some sort of a proof of identification to even have access to a mobile phone account, whether that is through their passport or some sort of a national ID. I ask Ms Blackwell and Ms Murphy's thoughts on it or those of whoever else wants to come in on it. I am really curious to know how they think we could get around those two issues.</p>
        </speech>
        <speech by="#" eId="spk_7">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T12:50:00+00:00"/></from>
          <p eId="para_36">Recommender systems are addressed within the Article 28 guidelines. The problem is the language. It does state that children should not be subject to addictive technologies and talks about prioritising explicitly stated interests over implicit data inferred from profiling. The issue will come down to that word “prioritise”. How do we prove they did not prioritise when we come to investigate? As we have seen, there is so much evidence to suggest children are subject to harmful narratives through these recommender systems. Just today, the Ombudsman for Children published a report saying that in a survey of 700 secondary school students, 60% of them have been exposed to extremist ideologies online versus 6% in real life. That is a very clear differential that is not reflecting real life and it is sending them down these harmful rabbit holes. Other very good research by the Anti-Bullying Centre, led by Professor Debbie Ging, found mass harmful narratives related to masculinity and misogynistic-type content being served up to boys and young men through YouTube and TikTok. We need very clear language within the Article 28 guidelines, although they are non-binding. Children should not be subject to anything other than explicitly-stated interest and age-appropriate information. We need that clarity and we need to make sure companies are really on the hook if they do not comply with that. </p>
        </speech>
        <speech by="#" eId="spk_8">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T12:50:00+00:00"/></from>
          <p eId="para_37">I ask my colleague Ms Murphy to speak to the recommender systems, and then I will mention something about age verification. </p>
        </speech>
        <speech by="#" eId="spk_9">
          <from> Ms Alex Murphy<recordedTime time="2025-12-03T12:50:00+00:00"/></from>
          <p eId="para_38">Thanks for having me. Akin to what Ms Cooney was saying in regard to the recommender systems, because of what they are based on, we would prefer, in regards to minors, for online platforms to have them simply off by default, in order that they are not on in the first place. The way in which they manipulate users’ attention, and children's attention specifically, increases the harmful effects they have on them. There is also the fact that because the Article 28 guidelines are non-binding, but they are also open, as Ms Cooney mentioned, it is left to the platforms essentially to prioritise, and what all of the platforms are doing with recommender systems is maximising their predicted engagement. The route to maximising predicted engagement is by trying to predict in advance what will get the most clicks, likes and shares. As this is driven by artificial intelligence, what the artificial intelligence has realised is that what is going to get the most clicks, likes and shares is harmful or extreme content - something that is shocking. That is what captures the user's attention and keeps them engaged. The entire goal, essentially, of the recommender system is to keep pushing this content because it is fulfilling its job. It is getting the clicks and likes, and because of the way the design of the platform is using this, it is kept on a loop, consistently taking children's attention towards it. We would prefer it was banned or completely off by default. Taking a children's rights-based approach, if children would like to have them on-----</p>
        </speech>
        <speech by="#EvanneNiChuilinn" eId="spk_10">
          <from>Senator Evanne Ní Chuilinn<recordedTime time="2025-12-03T12:50:00+00:00"/></from>
          <p eId="para_39">Is Ms Murphy suggesting an opt-in, so that by default, they are just not there and the user would have to opt in?</p>
        </speech>
        <speech by="#" eId="spk_11">
          <from> Ms Alex Murphy<recordedTime time="2025-12-03T12:50:00+00:00"/></from>
          <p eId="para_40">He or she would have to opt in. However, if he or she were to opt in, it would only be explicitly user-based engagement signals. A child would have to select what content they are happy to be put on them. It cannot be implied. Implied user-based engagement singles are generally collected by data or privacy scraping. It is the system implying what it thinks would be associated. However, it goes beyond that, because it pushes harmful content anyway, because that is what is going to get to clicks. Beyond that, artificial intelligence does a lot of data scraping and not protecting children's privacy because it is taking some of the engagement on different areas of the platform and using it to push content on them, whether in advertising or content-wise.</p>
        </speech>
        <speech by="#EvanneNiChuilinn" eId="spk_12">
          <from>Senator Evanne Ní Chuilinn<recordedTime time="2025-12-03T12:50:00+00:00"/></from>
          <p eId="para_41">I understand what Ms Murphy is saying about choosing what you want to be fed, but I am not sure whether children should be allowed to choose what they want to be fed, either. In terms of what is even available to be selected by them, we are back to age verification.</p>
        </speech>
        <speech by="#" eId="spk_13">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T12:50:00+00:00"/></from>
          <p eId="para_42">It is very much tied into that. The Article 28 guidelines that everyone is talking about did not descend from the sky. It really was a political decision to expand what the Digital Services Act needed to regulate to put those guidelines in place. If they could be put in place, more specific guidelines could equally be put in place at a political level. They are politically driven. It is a question of the pushback from the regulator.</p>
          <p eId="para_43"> The other point is, of course, the age verification. We need to know who a child is. We are advanced, but we are not at a point where we have good systems of recognising who is a child. There is good work, which I know the committee has heard about, being done at European Union Commission level, where they expect to have something in place by the end of 2026. Our own Office of the Government Chief Information Officer is also working on something which would produce something whereby all the platform would need to know about a user is they are over an age, that is, 13, 16, 18 or whatever, because the big issue for a lot of people is the amount of data that they are handing over to a platform in order to identify whether they are over or under 18. If a person can get these new systems in place, from their phone they should be able to scan a barcode into a website or whatever. </p>
          <p eId="para_44">It says the user is over a certain age, and that is all that is needed. It looks like a solution. It cannot be the only solution, though. There will be people who would deny the Government the right to know their name today. Why should they have to give more information to the State than they want to? There will need to be trusted third party operators certified by, say, the Data Protection Commission or someone like that to be privacy preserving as well as effective. All those things are on the move.</p>
          <p eId="para_45"> In the meantime, we believe, as far as we can see, that as regards Coimisiún na Meán, on platforms based in Ireland, the age assurance regulation is in place in relation to adult and seriously violent content. Coimisiún na Meán should find that all platforms regulated here have in place adequate age verification, not just self-declaration, but then the Netherlands has a different system and Malta has a different system. There is still a distance to go, and it is a key thing that will make it safer for children when there is a system, but the platforms, if they wanted to, could fix it in a week.</p>
        </speech>
        <speech by="#JoannaByrne" eId="spk_14">
          <from>Deputy Joanna Byrne<recordedTime time="2025-12-03T13:00:00+00:00"/></from>
          <p eId="para_46">I thank the witnesses for being with us. Sticking with that topic of conversation, nowhere in either opening statement references or advocates for a ban on under-16s on social media platforms. I am sure both organisations have seen the comments from the Tánaiste, in particular in recent months, but also from other Teachtaí Dála in that regard. I would be interested to hear their views on that. Particularly, Ms Cooney has referred to the huge number of young people her organisation has engaged with, I think over 100,000, as well as parents and educators and everybody who is involved in that circle, as I am sure Ms Blackwell's organisation engage with as well. I would be interested to hear the views of both organisations on that if possible.</p>
        </speech>
        <speech by="#" eId="spk_15">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T13:00:00+00:00"/></from>
          <p eId="para_47">In relation to a ban, the wording is problematic for me. I think it is a blunt instrument and it takes away from the fact that we need very real change within those online environments. Just excluding children from them does not bring the changes we want to see. What we do want to see, however, is proper independent assessment of these digital environments for risk, which is within the language of the Digital Services Act, that it is a risk-based assessment but there is an independence to it. Currently, the Article 28 guidelines allow the companies to self-evaluate their level of risk. If you are an adult content provider, it is clear you are high-risk and, therefore, you should be age-verifying for 18 and above. It gets a little greyer below that as to whether you are medium or low risk and what you then need to put in place. To our mind, that should be independent, a bit like the film classification board, in that there is an independent assessment of the risks that your digital environment poses to children specifically under the protection of minors and then an appropriate age determined for that. Is it 13 to 16? Is it 16 plus? For example, you might look at AI-generated chatbots, which pose so many similar risks to the recommender system in terms of engagement above all else that you might put those as high risk and age gate to 16 or 18. You might look at environments where the contact between adults and children is greatly facilitated and you might consider those to be higher risk environments and age gate them appropriately. It is not a random age applied; it is more based on the risk posed, which is in line with the European framework. We may well need to put minimum age into some sort of legislation, as have Italy, Spain and France, or as they are in the process of doing. The challenge is that we do not host the adult content providers in Ireland generally. X does allow for adult content, so we will be allowed to impose age verification requirements on it, but as for others, how do we ensure, with the pace at the European level, that we are reliant on the countries that host those providers to lead the way in terms of imposing age verification requirements? How do we stop children in Ireland being able to access highly inappropriate content? It is not just the very large companies, as I said in the opening statement. There are these AI girlfriend companion-type apps, which are adult content as well. There was research done last year by Concordia University - I referenced this earlier - which looked at 21 such apps. Not one had age verification in place. You can imagine the type of content that is available within those apps. Not one had age verification and several also continued to serve content even though they knew it was a child. Once the age was clear, they continued to serve content. It is a wild west in that regard and we need to look at urgent measures to protect children from some of this more harmful content.</p>
        </speech>
        <speech by="#" eId="spk_16">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:00:00+00:00"/></from>
          <p eId="para_48">Of course, I agree with a lot of what Ms Cooney said. Looked at just from the point of view of a child and children's rights, there are real problems with just saying we should ban children from the world in which they live and ban them from the right to instruction, the right to engagement, the right to education, the right to inclusion - all those things, as members know very well. It is what causes the dilemma. Then what do you ban? Do you ban this company but not that company? Do you add in that company? Do they change their name? Where do children who are banned go? For all that we complain about the regulation that is there now, do they go to less regulated companies if they cannot access the world in which they live? If we ban children from access to the digital environment until they are a certain age, we leave them in a place where they have to deal with that digital age. Australia's ban comes into place next week. A lot of academics there would say that 16 is an awful time to put a child free in the digital world when they are just trying to decide where they are going next. It is the age of matriculation and all those kinds of things.</p>
          <p eId="para_49"> In some ways, it is not the companies we should be banning; it is the functions that Ms Alex Cooney was talking about. That is actually what the regulators do, but we have this dilemma that we are worldwide and that the systems in, say, the United States, which is the home of so many of these companies in the first place, see freedom of speech in a very different way from the way we see it here in the European Union and the European Court of Human Rights area and in the context of the European Convention on Human Rights. What we should be banning are the nasty functions. That is why we have to look at how we are regulating those functions, how we are empowering the regulator to ensure that the risk assessments that are done are correct and how we do not censor children rather than putting sufficient pressure on the tech companies. Ireland can develop effective ways of age verification quite fast, and an awful lot of the companies have a ban on children under 13 accessing them, so they are not supposed to but they do.</p>
        </speech>
        <speech by="#JoannaByrne" eId="spk_17">
          <from>Deputy Joanna Byrne<recordedTime time="2025-12-03T13:00:00+00:00"/></from>
          <p eId="para_50">I have a final question to both organisations. Something that has come up in the conversation about this potential ban in recent months is concerns about contravening the UN Convention on the Rights of the Child and, in particular, their right to participate and their rights in the digital environment. I presume the witnesses would have concerns if there were an outright ban that that is essentially what we would face.</p>
        </speech>
        <speech by="#" eId="spk_18">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T13:00:00+00:00"/></from>
          <p eId="para_51">It is about balancing the right to participate in the online world. As Ms Blackwell said, they are growing up in a digital age and we need to acknowledge that, but we absolutely need to address the multitude of harms they are facing in the online environments and protect them from those harms in order that they can enjoy and thrive in these digital spaces. We have adapted a lot of the offline world for children's safety, protection and enjoyment. We need to do the same in the online context.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_19">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-12-03T13:00:00+00:00"/></from>
          <p eId="para_52">All the witnesses are very welcome. I thank them for their opening statements. I have so many questions, I do not know how I will distil this, but I will open with some of my concerns about age verification. I know I have shared them with some of the witnesses already, but maybe I will go into a bit more detail.</p>
          <p eId="para_53"> I will start off on the point we have just left, which is the children's rights point of view, the participation and the idea that a ban would essentially block children but also just create a barrier that we know they would overcome in whatever way. If they cannot get into it on their own phone, they will find another phone to get to it, so I have issues with it from that perspective. I know that CyberSafeKids is putting forward this concept of a third party verifier. I want to hear more about it. It might be something we could consider looking at for the schedule if it were possible to get one of these providers in to understand it in a bit more detail.</p>
          <p eId="para_54">I have consulted with some engineers in this space and one of the issues is that a consolidation of very precious data is created, which is in itself a target for hackers. I appreciate the way it was described, which is that they kind of ephemerally hold on to the data, but they still hold on to the data. They have to do so in some way to make it useful to have that kind of connection with users and their age. I have major concerns about that. Fundamentally, it leaves behind the cesspit that we are trying to protect children from, so that vulnerable adults - indeed all of us as adults - are still exposed to that nastiness online. For me, age verification is something that has been touted, but it is a plaster on a gaping wound. It is a tiny piece of the puzzle. I am not trashing it. We do not need to rule it out, but I have major concerns with it.</p>
          <p eId="para_55"> Some of the other issues I would love to hear the witnesses thoughts on more broadly include addiction. We are now seeing documents come out that clearly say that these tech companies know that their platforms are addictive, and they in fact encourage that addiction. Only on pain of legal action will they release that. In particular, I am familiar with the case of Adam Raine and the very sad story of his suicide. I do not know if everybody in this committee is as familiar, so it would be worthwhile hearing a little bit more about that and whether in particular teenagers and children in this jurisdiction are open to that? Is that happening right now and do we have the legal framework to deal with it?</p>
          <p eId="para_56"> All of this brings me to the point that the business model is the floor. I wonder if, as experts, whether the witnesses think we can find the resolutions within the existing model, or if it is the business itself that needs to be addressed. We are at a stage where technology is so integral in our society that we need to think about the nationalisation of this as a utility. I realise how radical that might sound to people, particularly people in government right now, but that is honestly where I am starting to head towards. That is a bit of a hotchpotch. There are not specific questions, but it is more to just put those thoughts to the witnesses and get their responses. Perhaps I could start with Ms Cooney from CyberSafeKids.</p>
        </speech>
        <speech by="#" eId="spk_20">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T13:10:00+00:00"/></from>
          <p eId="para_57">They are all interrelated.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_21">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-12-03T13:10:00+00:00"/></from>
          <p eId="para_58">Yes.</p>
        </speech>
        <speech by="#" eId="spk_22">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T13:10:00+00:00"/></from>
          <p eId="para_59">It is important to address them. On the age verification point, one interesting thing that happened this year was the trial in Australia. They were really looking at whether the technology had reached the kind of threshold that it needed to be at to be able to enforce the legislation that they are putting in place this month. The conclusion does seem to be that the technology has reached that threshold. They had their criteria, and privacy preservation was a key element in that, as well as the data retention policies. Big companies took part in that trial, which was an open trial, but there is a question mark around it, which is why we are advocating for a third-party solution, so that it would work against you if you come from big tech and you want to implement your own solutions, because there is no trust around how they manage our data, what they do with it and how they use it. Trusted third parties is the way, and that you have European-----</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_23">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-12-03T13:10:00+00:00"/></from>
          <p eId="para_60">Does, Ms Cooney accept that they then become vulnerable and open to attack in and of themselves?</p>
        </speech>
        <speech by="#" eId="spk_24">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T13:10:00+00:00"/></from>
          <p eId="para_61">Absolutely, and they need to be able to answer questions around how they manage that. I have spoken to an Irish provider that took part in the Australian trials and they would argue that they have very robust structures in place to manage that, and they get rid of as much as possible. The Deputy's suggestion to have such providers in before the Oireachtas could be really useful, because members could kind of grill them on some of these aspects.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_25">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-12-03T13:10:00+00:00"/></from>
          <p eId="para_62">The other point is that if it goes back into the private sphere, ultimately they are all working towards profit, and if a company is successful as a third-party age verification provider, they are going to become as big as the other tech companies and we are ultimately not going to have that same balance. Does Ms Cooney see what I mean? I have concerns over that.</p>
        </speech>
        <speech by="#" eId="spk_26">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T13:10:00+00:00"/></from>
          <p eId="para_63">A couple of things could be in place. One is that it is Europe wide.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_27">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-12-03T13:10:00+00:00"/></from>
          <p eId="para_64">If Ms Cooney does not mind, because I only have a certain amount of time, I might ask her to move on to the other questions as well. I am sorry.</p>
        </speech>
        <speech by="#" eId="spk_28">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T13:10:00+00:00"/></from>
          <p eId="para_65">Addiction is the engagement-based model, and that is the recommender system and AI chatbots. That is the number one focus. For good or for ill, that is what is driving everything. I do not think anyone is saying that the major tech companies are going out to harm children deliberately, but unfortunately it is a consequence of that design.</p>
          <p eId="para_66"> Children are using AI chatbots. We published data this year that showed 26% of eight- to 12-year-olds are engaging with AI chatbots and 36% of 12- to 15-year-olds, so we know that they are actively doing it. There has been a huge rise in use over the last year.</p>
          <p eId="para_67"> The Adam Raine case is worth highlighting because his queries at the outset were just homework queries. That is the thing that children tell us, that their number one purpose for it is homework. The second is just looking up information and the third is to chat. Over a relatively quick period, between September-----</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_29">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-12-03T13:10:00+00:00"/></from>
          <p eId="para_68">Six months.</p>
        </speech>
        <speech by="#" eId="spk_30">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T13:10:00+00:00"/></from>
          <p eId="para_69">Yes...he had taken his own life. What is really concerning in that case is that, allegedly, the chatbot mentioned the word "suicide" six times more than he did. It discouraged him from seeking help and it suggested that it loved him more than even his closest family members. It is deeply disturbing the idea that our children are exposed to this, and that from one day to the next it was rolled out to popular apps that they are already using like Snapchat and WhatsApp. That is really concerning.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_31">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-12-03T13:10:00+00:00"/></from>
          <p eId="para_70">I will make another point before I come to the Children's Rights Alliance. When we talked about recommender systems and algorithms, we got into a bit of detail about it earlier, but algorithms are not a bad thing. In fact, they are just a mathematical function. The difficulty is that those tech companies are designing algorithms to keep our eyes on the screen. What if we had control over the algorithms, like Senator Ní Chuilinn was talking about, the kind of opt-in and that children could be limited as to what they could design? If we as a State could design algorithms for social cohesion, educational advancement and for employment opportunities, we could have a tool that functions for the State not for profit. That is one of the most liberating ideas for us to think about taking this technology and applying it in a way that benefits society. It is really exciting but there is no way it is going to happen as long as it is in the hands of the tech companies. I am sorry. I know I have run out of time, but perhaps I could just see if the Children's Rights Alliance has anything to add.</p>
        </speech>
        <speech by="#" eId="spk_32">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:10:00+00:00"/></from>
          <p eId="para_71">I will respond very briefly on the business model. That really is a visionary solution. In the meantime, we must remember that what we are talking about here is platforms because the whole area is based on a commercial model. The current regulation is based on the e-commerce regulation. E-commerce says that there will be a platform for online sellers, but it will not be responsible for the stuff that people put up. That is what we are stuck with right now. We are stuck with a model that suits business because anyone can put up anything without the platform being held accountable and without the person who puts it up being held accountable. If we had to get to Deputy Gibney's solution, we could say we would get rid of that and we would require the platforms to be accountable for what they publish, like a broadcaster is responsible for what they publish. We could say that those who put stuff up cannot do it anonymously and without being accountable themselves. We would then make it at least as accountable as online broadcasting and that is not a huge stretch. The model of bringing social content in under the commercial model does not serve anyone, let alone children.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_33">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-12-03T13:10:00+00:00"/></from>
          <p eId="para_72">I thank Ms Blackwell.</p>
        </speech>
        <speech by="#AlisonComyn" eId="spk_34">
          <from>Senator Alison Comyn<recordedTime time="2025-12-03T13:10:00+00:00"/></from>
          <p eId="para_73">I thank all the witnesses so much for coming in here today. Not to diminish the work of anybody else, but I have always been a huge fan of Ms Blackwell's previous work in her role in the Dublin Rape Crisis Centre. I am hugely encouraged to see her here across this. I do believe we are in the grip of a crisis. I would love to see this committee room full so that we could all get across it.</p>
          <p eId="para_74"> As we did last week with Coimisiún na Meán, my colleagues have touched on holding the platforms to account. I am not going to let them off the hook with that, but for the moment, I am just going to speak for the parents. Fianna Fáil is taking this extremely seriously. I am on a committee that is working closely with parents to see how we and parents can learn and what we need to be doing. The results of our Parenting in the Digital Age survey came out yesterday. To just give a brief synopsis, it is clear that parents are hugely outpaced by technology. Only 18% feel equipped to help their child manage online risks, 75% support a full school smartphone ban and less than one third of parents never discuss their child's social media use with them. Clearly, we are in the grip of a crisis and we need to educate everybody. I am going to ask the witnesses for their comments - how they can help us, and how we can help each other to help the parents because clearly they are floundering. We can then look towards the children as well. In the opening statement of the Children's Rights Alliance, Ms Blackwell stated holding platforms to account requires "child-friendly, accessible systems to allow children to easily report harmful content". Is that not placing too much responsibility on the child? Here we are trying to educate the parents, and the children are so far ahead of it, and yet we are leaving it to them. We are saying that they are too young to be on these platforms, perhaps they should be banned from holding social media accounts and there is no proper age verification, yet we are leaving it to them to report harmful content. There are two strands there.</p>
          <p eId="para_75">I would love to hear the witnesses' take on parenting in the digital age and on the onus on children to report.</p>
        </speech>
        <speech by="#" eId="spk_35">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T13:20:00+00:00"/></from>
          <p eId="para_76">There was a survey earlier this year by Block W and the ESRI that looked at parenting in the digital age. It considered some 4,000 pieces of research and there was some really interesting stuff. One of the findings was that parents are struggling to mediate their own technology use, which means it will be all the harder to mediate their children's use. That is one point to bear in mind.</p>
          <p eId="para_77"> The other point that stood out for me in the report was that even with the best digital parenting skills in the world, people cannot do it on their own. We need fundamental changes for children within digital environments. We can equip, educate and guide them but, ultimately, they will be in those digital environments independently at some stage, so we must ensure they are made safer and more appropriate for them.</p>
          <p eId="para_78"> We have talked to lots of parents over the past decade and we definitely get feedback that there is a strong feeling of being overwhelmed, that their children know more than they do and that parents are on the back foot. However, over the past year or so, we have seen the growth across Ireland of, for want of a better description, hold-off movements. They can be parent-led or school-led but they are based around school communities. They involve groups of parents coming together and deciding they will hold off a little longer on giving their children a smart device or access to the likes of Snapchat. We are starting to see a real difference in our numbers. For the first time, we saw a drop in the data we published in terms of the number of children under the age of 13 who own a smartphone. I caveat that by noting that the number of under-13s who have smart devices remained steady at 93%. However, there was a drop specifically in smartphone ownership from 49% to 39%. Interestingly, underage usage of social media also dropped. Last year, we reported that 82% of under-13s had at least one social media and-or instant messaging account in their name; this year, it was 71%.</p>
          <p eId="para_79"> There is something to parents coming together and agreeing, in the best interest of their kids, to hold off on access to this technology. We have seen children with really early independent access and there is huge vulnerability there. We talk a lot about children using devices in their bedroom. Many kids tell us there are no rules for them in this regard and that they can bring their device to their room at night. That unfettered, unsupervised access is a problem. We need to better support parents, we need awareness campaigns and education in schools and we must support the parents trying to make changes.</p>
        </speech>
        <speech by="#" eId="spk_36">
          <from> Ms Martina Walsh<recordedTime time="2025-12-03T13:20:00+00:00"/></from>
          <p eId="para_80">Ms Cooney has spoken about our view that there should be age-gating of social media use depending on the content and functionality within the different platforms. If that is not the approach taken and if it is decided a ban is the way to go, any loophole that enables parents to allow a child access undermines any such ban. The situation currently is that Ireland has a digital age of consent of 16, yet every 13-year-old is on social media. If the discretion is left to parents, I am afraid there will be no change.</p>
        </speech>
        <speech by="#AlisonComyn" eId="spk_37">
          <from>Senator Alison Comyn<recordedTime time="2025-12-03T13:20:00+00:00"/></from>
          <p eId="para_81">We spoke outside the meeting about how every one of us has had frustrating experiences in this regard. Only in recent days, I saw a baby who could not be more than three or four months old beside me at a table being taken off its mother's breast and having a phone propped up in front of it. I am a parent and I do not mean to judge but where do we draw the line? On the Luas yesterday, I saw a child glued to a screen. Are we, as legislators, supposed to tell parents how to parent? We are starting to see the detrimental effects of this behaviour. Sometimes, the discretion of parents is clearly not enough.</p>
        </speech>
        <speech by="#" eId="spk_38">
          <from> Ms Martina Walsh<recordedTime time="2025-12-03T13:20:00+00:00"/></from>
          <p eId="para_82">I agree. In regard to digital literacy, Ms Cooney mentioned the Finnish model. Our view is that digital literacy skills need to be rolled out across the population and especially for young people. There is a huge amount that can be done in this regard and it can really change how they interact with social media.</p>
        </speech>
        <speech by="#AlisonComyn" eId="spk_39">
          <from>Senator Alison Comyn<recordedTime time="2025-12-03T13:20:00+00:00"/></from>
          <p eId="para_83">As well as looking at that, I also asked about leaving the option to the child to report harmful content.</p>
        </speech>
        <speech by="#" eId="spk_40">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:20:00+00:00"/></from>
          <p eId="para_84">A fact to note, which is irrelevant in some ways but relevant in others, is that a child in this country can be tried for murder or rape at ten years of age. There is already a level of obligation on children at a very young age.</p>
          <p eId="para_85"> On the question of raising the literacy and awareness of everybody, the witnesses from CyberSafeKids spoke about the Finnish model. There are a lot of resources out there. Coimisiún na Meán is putting together some really good resources, Webwise has some fantastic resources and CyberSafeKids provides resources. All of that can be overwhelming. Where are parents to go, which particular resource should they follow and how are they supposed to do it? How do parents know what to do about this if it is as much as they can do in the morning to get the children up and give them their breakfast? While there is a lot of lip service given to digital and media literacy and awareness, there is very little co-ordination in this area. We need a proper nationwide campaign, as we sometimes have on health matters such as flu injections for children, with information coming out of every single corner, including social media and general media, people going into schools to provide training and a consolidation of resources. That would let parents chill a bit because, in fact, they probably know more than they think they know. They get paralysed with everyone telling them they must use such-and-such language and so on. I will leave it at that.</p>
        </speech>
        <speech by="#AlisonComyn" eId="spk_41">
          <from>Senator Alison Comyn<recordedTime time="2025-12-03T13:20:00+00:00"/></from>
          <p eId="para_86">However, before putting out a strong message, we must all agree on what the message should be.</p>
        </speech>
        <speech by="#" eId="spk_42">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:20:00+00:00"/></from>
          <p eId="para_87">Yes, we must. We also have to say the message is probably simpler than it is being made out to be. People do not know where to look if they are given a long list of resources. Having a bank of digital resources that is better co-ordinated could be a recommendation coming from this committee.</p>
        </speech>
        <speech by="#AlisonComyn" eId="spk_43">
          <from>Senator Alison Comyn<recordedTime time="2025-12-03T13:20:00+00:00"/></from>
          <p eId="para_88">Perhaps a strong, clear ban on certain activities or much clearer guidelines would really help.</p>
        </speech>
        <speech by="#" eId="spk_44">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:20:00+00:00"/></from>
          <p eId="para_89">Clear guidelines for parents would be really good. Children also need to understand better about AI. There is no doubt they are engaging with the digital world. We must work out a way of managing this that is not another imposition on teachers to produce it all. A whole-of-school response is needed. A lot of work is going on in this area by Coimisiún na Meán, Webwise and others but it is all sort of split up in various ways.</p>
          <p eId="para_90"> On the question of accountability by children, we and our members are told by children that they report all the time but they do not know what happens to those reports. When they see nasty stuff online, the smart ones know how to report but they see nothing coming of that. Children can do that reporting. It should not be just up to them but they are well able to do it and, sometimes, they prefer that to telling parents or somebody else. That is the way of children.</p>
          <p eId="para_91"> If the Chair will allow it, I have one last point to make. An independent complaints mechanism is for child reports and not necessarily about reports by children. That mechanism is not in place. I urge the committee to recommend it be put in place now. The legislation is four or five years old. An expert group was put in place and Coimisiún na Meán is looking at it. However, I have not heard it discussed at this committee in the past few weeks. It is important.</p>
        </speech>
        <speech by="#MalcolmNoonan" eId="spk_45">
          <from>Senator Malcolm Noonan<recordedTime time="2025-12-03T13:20:00+00:00"/></from>
          <p eId="para_92">I apologise for missing the opening statements. I am caught between two committee meetings. If my questions have already been asked, the witnesses might stop me and we can move on.</p>
          <p eId="para_93"> In terms of the legislation applying only to Ireland based on companies that operate in Ireland, there tends to be a focus on the larger social media companies. My family's experience is that a lot of young people are accessing Snapchat and Roblox, with the latter increasingly becoming a social media platform. How will platforms be brought into the process as they change and evolve to try to sideline the regulations?</p>
        </speech>
        <speech by="#" eId="spk_46">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T13:20:00+00:00"/></from>
          <p eId="para_94">We describe the platforms as social digital environments, which captures video sharing, gaming, social media and instant messaging. Even the likes of WhatsApp, in our view, is increasingly morphing into a Snapchat-type model with its disappearing messages and AI features. To capture them all, we should be talking about the digital environments into which children are going. The Senator is right that Roblox is the most popular digital environment for children under the age of 13 in Ireland. It does not come under our national legislation because, first, it is not described as a video-sharing platform and also because it is not based in the State. Snapchat, likewise, is not in the State. Both come under the EU's Digital Services Act, with Snapchat, which is considered very large, being subject to the more stringent regulations, but it would not be on our Online Safety Commissioner to co-ordinate or enforce that. Roblox does not meet the size threshold of "very large", which means it is not even subject to risk assessments. That is a huge omission. Anywhere online that children are gathering in any numbers should be subject to a child rights impact assessment and, ideally, an independent one.</p>
          <p eId="para_95">Going back to the language, it is not something they get to do on their own, which is, unfortunately, the way it is set out at the moment in the Article 28 guidelines. There are real gaps in terms of capturing all the places children are visiting online.</p>
        </speech>
        <speech by="#MalcolmNoonan" eId="spk_47">
          <from>Senator Malcolm Noonan<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_96">I agree with that. Listening to my son and his friends, Roblox seems to be the platform of choice. There is an increasing need in this regard. A recommendation from this committee as matters evolve could be that they should all be brought under a regulatory regime.</p>
        </speech>
        <speech by="#" eId="spk_48">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_97">We have to remember that a good bit has been done over the past few years. Ireland's online safety code has not even been fully in place for six months. I do not think we can really say that we can confine the digital channels available to children in Ireland to those that are regulated here. Not to be Pollyanna, but the European Union has brought about quite a useful and wider regulation than is available anywhere else in the world. Even in the United States, there is not a uniform system. Regulation there depends on which state you live in. Our regulator is probably better resourced than most others in the European Union. Companies will go to wherever they are least troubled by regulators. That happened in the case of one designated company already. When Coimisiún na Meán designated it, it moved to the Netherlands. This committee can ask the State, for the next 18 months when it is on the agenda setting and agenda finding committee of the European Council as part of its Presidency of the EU, to take seriously better regulation Europe-wide. That is really where we will make most progress. If we get better regulation, we will get safer systems. It is trial and error, however. There is no great impact assessment in the context of the amount of regulation in place already. That will take time.</p>
          <p eId="para_98"> There is something about how we measure how children are doing. Are they a bit safer from harm now than they were a year ago, before the online safety code was in place, and before the Digital Services Act guidelines were put in place? We have to do something about that and we have to use that kind of information to better direct something that legislators let the tech companies take control of over a period of 20 years when we did not know what to do with it.</p>
        </speech>
        <speech by="#MalcolmNoonan" eId="spk_49">
          <from>Senator Malcolm Noonan<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_99">I agree with that. There is a need for ongoing longitudinal studies and research into the impacts of the regulations as they come through. That is important. I have a question about age-proofing. The Children's Rights Alliance called for effective but private age-proofing mechanisms to keep children safe from adult content. Individual privacy is often raised in these discussions in the context of protecting children from pornographic content. This matter may have already been raised.</p>
        </speech>
        <speech by="#" eId="spk_50">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_100">This has been touched on before, but it is an important topic. The companies that are regulated in the State now should have effective age verification in place. Coimisiún na Meán has already started a formal investigation into Twitter because it said it was going to leave its adult content available and started to put in place an age verification system. Coimisiún na Meán should be doing that. The others should be doing it in their place. Some of the big porn companies are not regulated in the State. The EU Commission has started proceedings against four of the big porn companies because of lack of effective age verification mechanisms. We are nowhere near there yet. However, the trouble is that we do not have the gadget that will allow somebody to just say to a platform that they are over 18, or 16 or 13. That is being worked on. The EU is working on one. The Irish State is also working on one. There will need to be trusted third-party providers for people who do not want to give their information to the State. They are not there yet.</p>
        </speech>
        <speech by="#" eId="spk_51">
          <from> Ms Martina Walsh<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_101">It might interest the Senator to know that a number of member states have gone ahead with their own national legislation to age-gate porn sites. Italy is the most recent one to do so. They have managed to move ahead on a national basis because they were not prepared to wait. They made sure that the approach they have taken is in alignment with the DSA and with the harmonisation route that is being pursued. There is nothing to stop Ireland, as far as we are aware, from looking into that and bringing something forward at national level.</p>
        </speech>
        <speech by="#MalcolmNoonan" eId="spk_52">
          <from>Senator Malcolm Noonan<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_102">We should include these recommendations in our report.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_53">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_103">Yes, quite a bit.</p>
        </speech>
        <speech by="#" eId="spk_54">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_104">I will add to that. One of the problems we have is that not everyone has a national ID card, so it is problematic.</p>
        </speech>
        <speech by="#" eId="spk_55">
          <from> Ms Martina Walsh<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_105">There are solutions around that.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_56">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_106">That is an issue in itself. We should have had one a few years ago, but that is a different discussion.</p>
          <p eId="para_107"> I thank the witnesses for their contributions. It is mind churning. I was taken aback by the commentary about the business modelling of this originating in e-commerce. I did an MBA in e-commerce in UCD in 1999. I was one of the first 20 graduates in Ireland. Online was basically e-commerce. That baseline has evolved to what we have now where whole social interactions are still based around e-commerce. The baseline is no longer correct for the social aspect or the regulatory process by which we deal with this.</p>
          <p eId="para_108"> I have two teenagers. My son used to love Roblox, but he has grown out of it. As a former IT manager, I am <i>au fait</i> with IT. It took me quite a while to put in place the systems to manage and look at what they were doing in their online space on their phones, iPads or whatever. I have not got everything, but I can do quite a bit of monitoring. They are happy that I am monitoring because we have that sort of relationship. I was taken by what Senator Comyn said. I am not bragging, but what percentage of parents have the capacity to do this?</p>
        </speech>
        <speech by="#" eId="spk_57">
          <from> Ms Martina Walsh<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_109">And to keep it updated. This is not a case of one and done.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_58">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_110">I have no clue about some of the things. I am on Snapchat just to see what my teenagers are at on Snapchat. I do not use Snapchat. Tomorrow there will be another Snapchat.</p>
          <p eId="para_111"> On age verification, there is a debate about whether we should have a ban or some form of age gating. Ultimately, there will be some way around it. We have to get to a point where we have regulatory processes, education and guidelines that are implemented. I do not believe you can come down with a hammer on this. I do not think that will work. It is impossible.</p>
        </speech>
        <speech by="#" eId="spk_59">
          <from> Ms Martina Walsh<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_112">It is all of those things. It is everybody seeing that it is all of the measures.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_60">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_113">It is almost like a pie chart where all the components have to come together for this to work. Then you have the Irish versus the EU versus the world. The idea that we can regulate certain companies based in Ireland is madness. What about the companies based outside Ireland? They are just going to move.</p>
        </speech>
        <speech by="#" eId="spk_61">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_114">If you compare it to something like road safety in Ireland, we have built an infrastructure around-----</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_62">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_115">That is not working very well either at the moment.</p>
        </speech>
        <speech by="#" eId="spk_63">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_116">Recent statistics are not great, but we have education in schools, we have legislation and awareness campaigns. We are focused, and it is societal. Industry is playing its part too. We need a societal approach. There is no silver bullet. Age verification is one thing; it is not the only thing for sure.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_64">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:30:00+00:00"/></from>
          <p eId="para_117">It is probably not the most important because someone will get around it.</p>
          <p eId="para_118">I was very taken by what Deputy Gibney said about nationalisation-----</p>
        </speech>
        <speech by="#" eId="spk_65">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_119">Yes, and there is-----</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_66">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_120">I am sorry; I was very taken by what she said about nationalisation. I do not suffer from the same issues she would as regards worry or concern in relation to if we have a centralised nationalised system for managing or for algorithms or all of that and it is something we could look into. Algorithms have the potential and capacity in many ways in our lives to be very helpful but in this scenario, obviously, because of the baseline, which I spoke about earlier in relation to e-commerce, the algorithms were only based on one thing. What are the witnesses' views on that?</p>
        </speech>
        <speech by="#" eId="spk_67">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_121">There has been some shift away from e-commerce as a basis. There is some recognition that the companies have responsibility but it is only when it is brought to their attention, rather than proactively ensuring that their products are safer. The US has similar cases going on around the design of platforms that section 230 would be like the e-commerce. It alleviates the companies of any responsibility for what is hosted. There is a very good documentary called "Can't Look Away: The Case Against Social Media", which profiles a law firm that is going after these companies on the basis. Their defence is that they are not responsible for the content that is on their platforms regardless of whether it came through a recommender algorithm. The law firm is basically saying that they are deliberately designing it this way, so I think they are trying to get around it that way. Our Digital Services Act and Digital Markets Act are supposed to be a kind of updating of that e-commerce premise but it is not going as far as it needs to go, for sure. As Deputy Gibney already said, of course we can train these recommended algorithms for something other than engagement and that is what needs to happen.</p>
        </speech>
        <speech by="#" eId="spk_68">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_122">What could we nationalise? We could nationalise what is within our own borders. It reminds me of the time when I only had access to RTÉ 1 living down in Tipperary and my cousins in Dublin had access to BBC and ITV.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_69">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_123">I am a slightly different generation but I had the exact same problem.</p>
        </speech>
        <speech by="#" eId="spk_70">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_124">I think it is a visionary thing. There could be public services. There is another discussion going on about whether we could have public service social media. Could we have it set up in the public interest? That is a real possibility that we could do it and that would probably be a halfway house-----</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_71">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_125">It should happen.</p>
        </speech>
        <speech by="#" eId="spk_72">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_126">-----but actually, there is a whole legal system in place already for online broadcasting, which is not perfect but where those who post content have to be responsible for it, where journalists can still protect sources where it is necessary to do that and where the platforms have to check before they put up defamatory or hateful product because if they do, they will be held responsible and held to account and fined. In all those cases, that makes them much more careful and it means that online television, papers and all those things are held to a much higher standard than if they call themselves a social media platform, and the systems exist already for it.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_73">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_127">I agree 100%. I often in my head, and it is kind of a weird thing, hope that there are going to be more court cases. </p>
        </speech>
        <speech by="#" eId="spk_74">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_128">Yes.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_75">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_129">It is a strange thing to say but one has to articulate that one hopes there are going to be more court cases because it is self-regulatory then. It is not self-regulatory, but it helps keep it between the ditches because people will become more conscious. If we look online, we are politicians, so I get it all the time. God knows, I could have sued. I was a Minister during a very difficult time and the world was different then even to now. However, there is a balance on whether someone is going to actually take action versus it being worth it for all the hassle in their family. Everyone knows that. That goes not just for personal reasons but for companies, content, copyright, Internet protocol, IP, stealing and everything like that. What I am seeing coming out of the discussion today and based on everything else is that in a way, there is a pie chart that needs to be put in place. I do not think a mallet is going to work as regards bringing in some sort of age ban like they are doing in Australia. It has to be based in some way around trying to influence the engineering and education. There is an issue here with health.</p>
        </speech>
        <speech by="#" eId="spk_76">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_130">Yes.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_77">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_131">I am putting that out. I think there probably is something based on data management. I am not sure what it is, but I think there is a component there which is based around data management. Doing that will influence, obviously, algorithms and recommendations. Then, all of that can be pushed on. Obviously, as Ms Blackwell said earlier, we have all the issues in relation to how people can put up content. There are regulations in relation to issues whereby people put up inappropriate content where they can be sued and all that sort of stuff. Therefore, if we can tighten in on a whole range of those issues in that pie chart, that is probably a better way to go. Would the witnesses agree?</p>
        </speech>
        <speech by="#" eId="spk_78">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_132">We are three decades into this digital environment. We just have to work it as best we can. New solutions may come up in five or ten years' time. Court cases will come up in four or five years' time but as the legislation is just in place, this kind of tightening and coalescing it all and trying to work on all the aspects of it is essential.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_79">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_133">One last comment is that we do need some form of consistency, and with this committee and this Minister there will hopefully be a way in which we can do this. We need some consistency of approach because that is a big issue too.</p>
        </speech>
        <speech by="#EvanneNiChuilinn" eId="spk_80">
          <from>Senator Evanne Ní Chuilinn<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_134">I am trying think of a couple of things that we discussed. This is all brilliant and it will really inform our report but some of it is really frustrating because we kind of never get to the end of finding a solution. How do the witnesses feel about digital literacy in schools and how we can support teachers? Should we be looking at digital literacy modules or programmes within existing subjects in school, not necessarily exam subjects but just in terms of social awareness and stuff and those subjects they already do in secondary school particularly?</p>
          <p eId="para_135"> My colleague, Deputy Keogh, is doing a bit of work on online safety. She is chair of the Joint Committee on Children and Equality. She was saying to me that she was in a school this week and the kids themselves were asking for an under-16 ban. We have to help the kids help themselves as well. I have three kids. One has a phone. He is nearly 14 but-----</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_81">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_136">I know.</p>
        </speech>
        <speech by="#EvanneNiChuilinn" eId="spk_82">
          <from>Senator Evanne Ní Chuilinn<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_137">I would be fairly strict but at the same time, he is out of the house a lot and if I restrict something on my Wi-Fi, he is going to get somewhere else. Another colleague who is a former teacher was telling me last night that they had a VPN ban in the school itself to not allow certain sites to be opened. One of the teachers managed to navigate it because she wanted to show the kids something but if the teacher is doing it then the kids can do it. They are more digitally literate than we are. I am trying to look at policy even within the education space. Is there something more we could push for that would help achieve some of the movements we still need on the safety stuff and the protections?</p>
        </speech>
        <speech by="#" eId="spk_83">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_138">I was at a Media Literacy Ireland conference only last week and there were some young people from schools represented there. On the education piece, they say they are not getting it. One said it was three years since they had a class on it. There is the idea that we have content but we are not routinely or consistently teaching it. If we were to reference back to the Finnish model, they have embedded it across the curriculum, so it is no longer a stand-alone topic that people may or may not cover. It is about fostering critical thinking skills really and applying them to the online environment, so, critically engaging with the content, fact-checking and knowing that there is going to be a quantity of misinformation and disinformation out there and using that. In English, we could be looking at persuasive language. In art, we could be looking at the manipulation of images, which are all so relevant in the digital context.</p>
        </speech>
        <speech by="#EvanneNiChuilinn" eId="spk_84">
          <from>Senator Evanne Ní Chuilinn<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_139">It is like integrating it into the curriculum or how we speak to kids.</p>
        </speech>
        <speech by="#" eId="spk_85">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T13:40:00+00:00"/></from>
          <p eId="para_140">It is integrating it. The focus is the upskilling throughout the curriculum.</p>
          <p eId="para_141"> Then, on the young people, what we find is that older young people tend to be more focused on a ban for younger kids and saying they should not have it under the age of 16 whereas the younger kids that we talk to still want that access.</p>
          <p eId="para_142">They are very enthusiastic about that access but there are loads of things they do not like about it. It is about that balance. It is about being able to have access without, as one 13-year-old put it, "rude content". She does not want to see rude content but is still exposed to it. We definitely need to find that balance.</p>
        </speech>
        <speech by="#EvanneNiChuilinn" eId="spk_86">
          <from>Senator Evanne Ní Chuilinn<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_143">I heard one of those young people on the radio this morning, after the ombudsman's report, talking about not wanting to hear certain things from their friends or to see some of the content that is being fired around.</p>
        </speech>
        <speech by="#" eId="spk_87">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_144">The Ombudsman for Children has done a good bit of work on child participation. May I add to the Senator's worries? In terms of the educational programmes the tech companies are bringing into schools, there are over 1,000 schools in Ireland with tech company-supplied programmes. None of these are licensed and there is no clear understanding of what happens to the children's data.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_88">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_145">That is very interesting.</p>
        </speech>
        <speech by="#" eId="spk_89">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_146">There is no clear understanding of where they fit into the curriculum.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_90">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_147">We will definitely be making a recommendation in that regard.</p>
        </speech>
        <speech by="#" eId="spk_91">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_148">There absolutely needs to be a licensing or quality control system in relation to those programmes. There also needs to be transparency around what happens to the information children give over.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_92">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_149">That is very important.</p>
        </speech>
        <speech by="#" eId="spk_93">
          <from> Ms Alex Murphy<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_150">To add something on literacy and to build on Ms Blackwell's first point, the programme for Government has expressed a large interest in using digital developments and artificial intelligence and increasing the role of ICT in education. The artificial intelligence that is going to be used in education system is deemed high risk but the roll-out of that legislation is likely to be slower than the actual embedding of artificial intelligence across the education sector. </p>
          <p eId="para_151"> Aside from that, the digital literacy aspect is critical. It is exactly like what the Cathaoirleach said about the pie chart. It is essential from the children's perspective and to take some of the pressure off teachers because we are seeing a lot of parents looking for teachers to show their children these things. The teachers might not know how.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_94">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_152">I am married to a teacher.</p>
        </speech>
        <speech by="#" eId="spk_95">
          <from> Ms Alex Murphy<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_153">The Cathaoirleach will probably be familiar with the issue then. Aside from that issue, we also have to think about the fact that vulnerable children are disproportionately affected by the online environment. Not every child has a parent or caregiver. Children in care are using social media and smartphones. That is beneficial because it can encourage connectivity but they are also disproportionately affected. The only way to address that is to embed literacy across all schools through a nationwide approach. Coimisiún na Meán and Webwise are doing great work but we need every single child to be aware of the dangers and where to seek help.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_96">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_154">I apologise for having had to step out. If my questions are repetitive and the witnesses feel they have been covered already, they should not feel obliged to answer. I will take the opportunity to touch on the regulatory framework again. We had Coimisiún na Meán in here. I get mixed up because we are covering very similar material at the Joint Committee on Artificial Intelligence so I cannot remember if it was in this committee or that one. However, the commission seemed very confident that it was resourced and empowered enough to do a good job. However, I detect from the opening statements and the witnesses' contributions that there might be areas the witnesses think need to be strengthened further. I would not mind hearing their take on that. How concerned are they about the digital omnibus proposal and the watering down of all of these protections at EU level?</p>
        </speech>
        <speech by="#" eId="spk_97">
          <from> Ms Martina Walsh<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_155">At a meeting of the Oireachtas Joint Committee on European Affairs in September, Dr. John Evans said that, if there was one thing he could change, he would like to have greater information gathering powers. Coimisiún na Meán has to open an investigation before it can compel the provision of information. We take the commission at its word when it says it needs greater information gathering powers.</p>
          <p eId="para_156"> The watering down of the legislation is definitely of concern. It is a feature of the environment we are in as regards tariffs, trade negotiations and all the rest of it. As a counterpoint, I do not know if members of the committee are aware but, last week, there was a vote in the European Parliament on a proposal by the shadow rapporteur for the Digital Services Act. The proposal points out a huge number of gaps in the Act and calls for maximum enforcement of its provisions. It also asks for additional regulation to be introduced in certain areas. The proposers take a strong line in relation to recommender systems. They believe they should be turned off. The proposal also refers to risk assessments and says there should not be profiling and so on. I recommend that people read the proposal if they get a chance. That vote passed overwhelmingly with 80% in favour. That will send a message to the Commission that-----</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_98">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_157">Is the Commission the issue really? The EPP, the ruling group, seems to be really backing this simplification agenda. There seems to be real pushback against bureaucracy. "Bureaucracy" and "regulation" seem to be thought of as bad words. That is my concern. We are saying that Europe is best in class when compared with China and Russia but we have heard in the AI committee that that is not the case. There are areas where protections in China are actually better than those in Europe. Moreover, the direction of travel is the other way before this has even started.</p>
        </speech>
        <speech by="#" eId="spk_99">
          <from> Ms Martina Walsh<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_158">Based on comments from Christel Schaldemose and other people in the parliament, they feel there is consensus when it comes to children and that there is a push to protect the regulation or to even go further. I hope that area will be protected from any watering down but we will have to see.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_100">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_159">Were Ms Murphy or Ms Blackwell going to jump in there?</p>
        </speech>
        <speech by="#" eId="spk_101">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_160">The Deputy is 100% right that the so-called simplification of the regulation is a real concern. As Ms Walsh said, measures affecting children should be exempt but that is not the case. I will push something that causes a problem in relation to the protection of children online. There is a polarisation between those who prefer the right to privacy to the protection of children and those whose priorities are the other way around. One of the things I would love to see Ireland doing is allowing a safe space where human rights activists and children's activists are not pitted against each other but can come to an understanding on how best to balance people's rights to privacy and children's rights to absolute protection from exploitation, torture and cruel, inhuman and degrading treatment. That tends not to happen.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_102">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_161">I am sure Ms Blackwell will be familiar with the AI governance set-up. As she and I know, this mimics the national preventative mechanism framework, where there is a co-ordinating body and then multiple human rights actors or agencies. Does that create such a space?</p>
        </speech>
        <speech by="#" eId="spk_103">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_162">It does but, over the summer, there were campaigns saying there cannot be interference with the right to encryption. That might be right but the right to privacy and the right to protection are still being pitted against each other, particularly at European Parliament level. It is something that could be done. It would be a fabulous showpiece for Ireland during the Presidency.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_104">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_163">That is a good point.</p>
        </speech>
        <speech by="#AlisonComyn" eId="spk_105">
          <from>Senator Alison Comyn<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_164">At the risk of upsetting one of my own Ministers, I want to find out the witnesses' opinions on measures like the phone pouches. I am as addicted to this yoke as the next person. It has to be prised out of my fingers. I have been at three events over the past 12 months where my phone has been put in a phone pouch and taken away from me, meaning I have to switch off and relax or focus on what I am doing at the time. It takes a while for my heartbeat to come down but it is the only time I am relaxed and switched off. What about that for our schoolchildren?</p>
        </speech>
        <speech by="#" eId="spk_106">
          <from> Ms Noeline Blackwell<recordedTime time="2025-12-03T13:50:00+00:00"/></from>
          <p eId="para_165">That is a mechanism that suited some schools and did not suit others. It showed that there is an increasing social understanding of the value of restricting phones in schools. Different schools would like to do it in different ways. Allocating budget resources for one mechanism, which did not suit everyone, therefore came in for criticism from children, teachers, unions and others. One of the ways the pie chart will work is that you will see that people are already making their own arrangements. Particularly in schools where children's parents are well-resourced, arrangements are being made to try to limit phone time in the same way as I was limited from bringing comics into school, although that did not stop me. Those things are starting to happen already and they are very welcome indeed. To pick up on my colleague Ms Murphy's point, it is not uniform across all children. Those who are more disadvantaged are likely to be more vulnerable to harm and less able to put those kinds of things in place. With all due respect to the Minister, that was micromanagement and it was unnecessary.</p>
          <p eId="para_166">However, the idea of building a consensus around limiting phone time in school is taking hold. My colleagues in CyberSafeKids are doing great work in this area as well because they insist that we all take a night off, which does not work for everybody.</p>
        </speech>
        <speech by="#AlisonComyn" eId="spk_107">
          <from>Senator Alison Comyn<recordedTime time="2025-12-03T14:00:00+00:00"/></from>
          <p eId="para_167">I would love to hear Ms Cooney's take on it.</p>
        </speech>
        <speech by="#" eId="spk_108">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T14:00:00+00:00"/></from>
          <p eId="para_168">We agree that the pouches are a singular solution. The sum of €9 million could probably have been spent on a broader range of measures to promote digital literacy or online safety. It is worth having very clear policies around the distinction between the personal use of devices during school time and the educational use of devices. We totally acknowledge that some children benefit from using technology to facilitate learning. We encourage learning about how to use technology in a safe way but the personal use of devices takes away from all the things that children are in school to do. It is about having that clear distinction and allowing schools to introduce whatever measures they feel they can and to engage with the school population on it. One of the things that came out of the Ombudsman for Children report on this specific issue is that there was not enough talking to children about what would work in the school setting. Schools can look at having policies where the phones are put away and what would happen if they are caught with it or whatever. A clear distinction is needed.</p>
          <p eId="para_169"> On the 24-hour cyberbreak from digital devices, we do encourage regular breaks. I want to add one point.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_109">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T14:00:00+00:00"/></from>
          <p eId="para_170">Yes, very quickly.</p>
        </speech>
        <speech by="#" eId="spk_110">
          <from> Ms Alex Cooney<recordedTime time="2025-12-03T14:00:00+00:00"/></from>
          <p eId="para_171">I just want to add to Deputy Gibney's point on the powers of Coimisiún na Meán. Something that we have discussed quite a lot already today is the individual complaints mechanism. It is provided for within the law, as Ms Blackwell has said, but the issue is the commission does not prescribe any kinds of timeframe around the handling of complaints. It basically just says that the timeframes need to improve. If you are to put an individual complaints mechanism in place, it is really important that the public know what is an acceptable timeframe for a complaint. We know that children do report content and then often do not hear responses. We want them to know that they can go and get a resolution through this mechanism, but we will need to be a bit more prescriptive around what is the expectation on companies in terms of their responsiveness and how they handle complaints.</p>
        </speech>
        <speech by="#AlanKelly" eId="spk_111">
          <from> An Cathaoirleach<recordedTime time="2025-12-03T14:00:00+00:00"/></from>
          <p eId="para_172">We will make that recommendation, too.</p>
          <p eId="para_173"> I thank the witnesses very much for today. It has been very enlightening. It was one of our best sessions. We have had some fairly long and intense sessions but it is good when we can get into the detail.</p>
          <p eId="para_174"> That concludes our public engagement for the day. We will now go into private session to deal with housekeeping matters. I will not keep members long but we do need to do some stuff.</p>
        </speech>
        <summary eId="sum_5"> The joint committee went into private session at 2.02 p.m. and adjourned at 2.14 p.m. until 12.30 p.m. on Wednesday, 10 December 2025.</summary>
      </debateSection>
    </debateBody>
  </debate>
</akomaNtoso>
