<akomaNtoso xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://docs.oasis-open.org/legaldocml/ns/akn/3.0/CSD13" xsi:schemaLocation="http://docs.oasis-open.org/legaldocml/ns/akn/3.0/CSD13 ./akomantoso30.xsd">
  <debate name="Official Report">
    <meta>
      <identification source="#debates">
        <FRBRWork>
          <FRBRthis value="/akn/ie/debateRecord/joint_committee_on_artificial_intelligence/2025-11-18/debate/main"/>
          <FRBRuri value="/akn/ie/debateRecord/joint_committee_on_artificial_intelligence/2025-11-18/debate"/>
          <FRBRdate date="2025-11-18" name="#generation"/>
          <FRBRauthor as="#author" href="/ie/oireachtas/committee/dail/34/joint_committee_on_artificial_intelligence"/>
          <FRBRcountry value="ie"/>
          <FRBRname value="debate"/>
        </FRBRWork>
        <FRBRExpression>
          <FRBRthis value="/akn/ie/debateRecord/joint_committee_on_artificial_intelligence/2025-11-18/debate/mul@/main"/>
          <FRBRuri value="/akn/ie/debateRecord/joint_committee_on_artificial_intelligence/2025-11-18/debate/mul@"/>
          <FRBRdate date="2025-11-18" name="#reported"/>
          <FRBRauthor as="#editor" href="#debates"/>
          <FRBRlanguage language="eng"/>
        </FRBRExpression>
        <FRBRManifestation>
          <FRBRthis value="/akn/ie/debateRecord/joint_committee_on_artificial_intelligence/2025-11-18/debate/mul@/main.xml"/>
          <FRBRuri value="/akn/ie/debateRecord/joint_committee_on_artificial_intelligence/2025-11-18/debate/mul@.akn"/>
          <FRBRdate date="2025-11-20" name="#publication"/>
          <FRBRauthor as="#editor" href="#debates"/>
        </FRBRManifestation>
      </identification>
      <references source="#debates">
        <TLCPerson eId="DarrenORourke" href="/ie/oireachtas/member/id/Darren-O'Rourke.D.2020-02-08" showAs="Darren O'Rourke"/>
        <TLCPerson eId="DeeRyan" href="/ie/oireachtas/member/id/Dee-Ryan.S.2025-01-29" showAs="Dee Ryan"/>
        <TLCPerson eId="JamesGeogheganFG" href="/ie/oireachtas/member/id/James-Geoghegan.D.2024-11-29" showAs="James Geoghegan"/>
        <TLCPerson eId="JohnnyMythen" href="/ie/oireachtas/member/id/Johnny-Mythen.D.2020-02-08" showAs="Johnny Mythen"/>
        <TLCPerson eId="MalcolmByrne" href="/ie/oireachtas/member/id/Malcolm-Byrne.D.2019-11-29" showAs="Malcolm Byrne"/>
        <TLCPerson eId="NaoiseOCearuil" href="/ie/oireachtas/member/id/Naoise-Ó-Cearúil.D.2024-11-29" showAs="Naoise Ó Cearúil"/>
        <TLCPerson eId="PaulMurphy" href="/ie/oireachtas/member/id/Paul-Murphy.D.2014-10-10" showAs="Paul Murphy"/>
        <TLCPerson eId="SineadGibney" href="/ie/oireachtas/member/id/Sinéad-Gibney.D.2024-11-29" showAs="Sinéad Gibney"/>
        <TLCRole href="role/chair" showAs="Chair" eId="Chair"/>
        <TLCRole href="role/vice_chairman" showAs="Vice Chairman" eId="Vice_Chairman"/>
        <TLCRole href="role/author" showAs="author" eId="author"/>
        <TLCRole href="role/editor" showAs="editor" eId="editor"/>
      </references>
    </meta>
    <preface>
      <block name="title_ga">
        <docTitle>DÍOSPÓIREACHTAÍ PARLAIMINTE</docTitle>
      </block>
      <block name="title_en">
        <docTitle>PARLIAMENTARY DEBATES</docTitle>
      </block>
      <block name="proponent_ga">
        <docProponent>TITHE an OIREACHTAS</docProponent>
      </block>
      <block name="proponent_en">
        <docProponent>HOUSES OF THE OIREACHTAS</docProponent>
      </block>
      <block name="committee_ga">
        <docCommittee>AN COMHCHOISTE UM INTLEACHT SHAORGA</docCommittee>
      </block>
      <block name="committee_en">
        <docCommittee>Joint Committee on Artificial Intelligence</docCommittee>
      </block>
      <block name="status_ga">
        <docStatus>TUAIRISC OIFIGIÚIL</docStatus>
      </block>
      <block name="status_en">
        <docStatus>(OFFICIAL REPORT)</docStatus>
      </block>
      <block name="date_ga">
        <docDate date="2025-11-18">Dé Máirt, 18 Samhain 2025</docDate>
      </block>
      <block name="date_en">
        <docDate date="2025-11-18">Tuesday, 18 November 2025</docDate>
      </block>
      <block refersTo="#unrevised" name="version_en">
        <docStatus/>
      </block>
      <block refersTo="#unrevised" name="version_ga">
        <docStatus/>
      </block>
    </preface>
    <debateBody>
      <debateSection name="prelude" eId="dbsect_1">
        <summary class="Center" eId="sum_1">Tháinig an Comhchoiste le chéile ag 11:00 a.m.</summary>
        <summary class="Center" eId="sum_2">The Joint Committee met at 11:00 a.m.</summary>
        <rollCall>
          <summary class="Center" eId="sum_3">Comhaltaí a bhí i láthair / Members present:</summary>
          <table>
            <tr>
              <th>
                <p eId="para_1">Teachtaí Dála / Deputies</p>
              </th>
              <th>
                <p eId="para_2">Seanadóirí / Senators</p>
              </th>
            </tr>
            <tr>
              <td>
                <p eId="para_3">
                  <person refersTo="#JamesGeogheganFG">James Geoghegan</person>
                </p>
              </td>
              <td>
                <p eId="para_4">
                  <person refersTo="#DeeRyan">Dee Ryan.</person>
                </p>
              </td>
            </tr>
            <tr>
              <td>
                <p eId="para_5">
                  <person refersTo="#SineadGibney">Sinéad Gibney</person>
                </p>
              </td>
              <td/>
            </tr>
            <tr>
              <td>
                <p eId="para_6">
                  <person refersTo="#JohnnyMythen">Johnny Mythen</person>
                </p>
              </td>
              <td/>
            </tr>
            <tr>
              <td>
                <p eId="para_7">
                  <person refersTo="#DarrenORourke">Darren O'Rourke</person>
                </p>
              </td>
              <td/>
            </tr>
            <tr>
              <td>
                <p eId="para_8">
                  <person refersTo="#NaoiseOCearuil">Naoise Ó Cearúil.</person>
                </p>
              </td>
              <td/>
            </tr>
          </table>
          <summary eId="sum_4">
            <person as="#Chair" refersTo="#MalcolmByrne">Teachta / Deputy Malcolm Byrne sa Chathaoir / in the Chair.</person>
          </summary>
        </rollCall>
      </debateSection>
      <debateSection name="debate" eId="dbsect_2">
        <heading>Artificial Intelligence, Truth and Democracy: Discussion<recordedTime time="2025-11-18T11:00:00+00:00"/></heading>
        <speech by="#MalcolmByrne" eId="spk_1">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T11:00:00+00:00"/></from>
          <p eId="para_9">We have received apologies from Senator Lynn Ruane. Colleagues will be joining us because other committees are going on at the same time.</p>
          <p eId="para_10"> There are the usual terms and conditions with regard to the committee, which members will be familiar with. For members who are here, there are constitutional requirements to be within the Leinster House complex. I am quite certain that our representatives know some of the rules with regards to privilege within the chamber.</p>
          <p eId="para_11"> Our role is to explore the issue and how it impacts on a wide variety of areas of society - indeed, it impacts on every area - and to offer recommendations to Government and the State on our approach and how we should interact with the private sector.</p>
          <p eId="para_12">We are operating in modular format and currently considering the issues of AI and the State. Today's session is particularly important where we look at AI and democracy and truth.</p>
          <p eId="para_13"> We are very fortunate to have a number of very experienced and insightful witnesses before us I welcome from An Coimisiún Toghcháin Mr. Art O’Leary, chief executive, and Mr. Nick Callan, assistant principal for electoral integrity; Mr. Jeremy Godfrey, executive chair, and Ms Anne-Marie Pollock, director of policy for democracy and fundamental rights from Coimisiún na Meán; Professor Muiris MacCarthaigh, director of the centre for public policy and administration, and Dr. Deepak Padmanabhan, senior lecturer in computer science at the school of electronics, electrical engineering and computer science at Queen's University Belfast; and Dr. Dan McQuillan from Goldsmiths in London. I thank all our witnesses for their time today. We are going to invite them now to make opening statements, which are to be four minutes, and we will then go to questions and answers from each member of the committee. I invite Mr. O'Leary on behalf of An Coimisiún Toghcháin to please deliver his opening statement.</p>
        </speech>
        <speech by="#" eId="spk_2">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T11:05:00+00:00"/></from>
          <p eId="para_14">Gabhaim buíochas leis an gCathaoirleach as ucht an cuireadh a bheith ag an gcruinniú tábhachtach seo. Chaith mé deich mbliana shona sa seomra seo agus is cúis áthais dom a bheith. I thank the Chairman for his very kind invitation to be with the committee today. I spent ten very happy years in this room in a previous life, so it is a great pleasure to be back again.</p>
          <p eId="para_15"> This is a timely moment for An Coimisiún Toghcháin. Only days ago, we concluded our public awareness work for the presidential election - our eighth electoral event in 33 months. Technology is accelerating and expectations are rising yet the central question facing us remains constant. Artificial intelligence, like every transformative tool since the stone axe, brings significant opportunity and undeniable risk, but when placed within the delicate machinery of democracy, those risks become sharper and the responsibilities heavier.</p>
          <p eId="para_16"> What do we talk about when we talk about AI? We talk about chatbots and deepfakes; synthetic text, voices and images; and extraordinary efficiencies and equally extraordinary vulnerabilities. We talk about how political actors might use AI, and how malign actors might weaponise it to distort debate or undermine confidence. Beneath all of that, however, we are really talking about one thing and that is trust. Trust is the foundation on which democratic legitimacy rests and in Ireland, that foundation is remarkably strong. Across a century, the State has built a widely shared belief that our elections are robust, lawful and independent. After November’s general election, 94% of respondents told us that elections are conducted in accordance with the law, 88% said they are well-managed and 96% expressed confidence in the secrecy of the ballot. These figures reflect decades of careful stewardship, and they represent a duty to protect that trust in every future electoral event.</p>
          <p eId="para_17"> We are exploring how AI can strengthen our own work and how it might support future constituency reviews, streamline analysis or improve how we communicate with voters. However, our approach begins with key fundamentals. Ireland’s paper-based system offers transparency and resilience, if not complete immunity, to digital interference. Our electorate - and the political actors who serve it - is thoughtful, informed and deeply engaged. They deserve partnership, not paternalism, and the sheer speed and scale of AI-generated content mean that monitoring and labelling alone will never be enough.</p>
          <p eId="para_18"> The final days of the presidential election illustrated this challenge vividly. A piece of AI-generated misinformation about the electoral process circulated rapidly and gained media attention. It showed how easily such content can be produced and how often we may see similar attempts. My friend and colleague, Tom Rogers, former chief executive of the Australian Electoral Commission, speaks of AI’s three Vs: volume, velocity and veracity. Information now moves faster, in greater quantities and with more subtle distortions than at any time in our history. Voters of all ages need support to navigate this new landscape. We will remain vigilant during the white-hot heat of election campaigns, where speed matters most, but our deeper task is to build long-term democratic resilience.</p>
          <p eId="para_19">Europe shares that mission. The European democracy shield's focus on protecting the information space, strengthening democratic institutions and boosting societal resilience aligns closely with our own priorities. For An Coimisiún Toghcháin, that third pillar of societal resilience stands at the heart of our education and public engagement strategy. We aim to reach people not only in formal education but in their communities, their workplaces and in the places where democratic participation can feel most distant.</p>
          <p eId="para_20"> We are committed to staying at the frontier of learning. Tomorrow, we meet again with European colleagues to share best practice on AI in elections. In the evolving relationship between democracy and artificial intelligence, three principles must guide us, namely, that trust is the foundation, vigilance is the duty and education is our common defence. Cuirim míle buíochas leis an gcoiste.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_3">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T11:10:00+00:00"/></from>
          <p eId="para_21">I thank Mr. O'Leary. I now invite Mr. Godfrey to deliver an opening statement on behalf of Coimisiún na Meán.</p>
        </speech>
        <speech by="#" eId="spk_4">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T11:10:00+00:00"/></from>
          <p eId="para_22">I thank the Cathaoirleach and the committee for the invitation to attend today. I am the executive chair of Coimisiún na Meán. I am joined by Anne-Marie Pollock, our director of policy for democracy and fundamental rights.</p>
          <p eId="para_23"> At Coimisiún na Meán, we aim to develop and regulate a thriving, diverse, creative, safe and trusted media landscape. The advent of AI is likely to impact on each of those elements. A healthy media landscape empowers citizens to make informed choices about the media they consume and the ways in which they consume it. This means exposing citizens to a variety of voices and opinions, enabling them to identify reliable sources of news and to understand how technologies such as AI play a part in choosing what they see and hear when they engage with media through online platforms or smart devices.</p>
          <p eId="para_24"> Democracy is one of the strategic outcomes set out in our initial three-year strategy. We want the media landscape to support democracy and democratic values, underpin civic discourse and reduce the impact of disinformation on our society. In the wrong hands, AI can undermine those aims. For example, the risks AI poses in this area include deepfakes being deliberately used to mislead voters, AI in recommender systems exacerbating echo chamber effects and amplifying the reach of misinformation and disinformation, AI being used to customise or target political messages in a manipulative manner, and AI chatbots being used as a source of news that produces content that is biased or inaccurate.</p>
          <p eId="para_25"> We have already been designated by the Government as a fundamental rights authority and a market surveillance authority for certain provisions within the EU AI Act in Ireland. We are in regular contact with relevant Departments as the new functions are implemented in Irish law and as we plan how we can use our new competences to support a healthy media landscape. The new AI Act's risk-based approach prohibits a range of AI practices that undermine fundamental rights, including using subliminal or purposefully manipulative and deceptive techniques to distort people's behaviour in a way that might cause harm or exploit vulnerable users such as children. There are also transparency obligations falling on providers and deployers of limited-risk uses. They include requirements for AI systems designed to interact with people to inform them of this, such as chatbots or chatbot assistants, and the labelling of AI-generated or manipulated content, such as deepfakes or AI-generated news summaries. This will apply to online platforms and broadcasters, among others.</p>
          <p eId="para_26"> Under the EU's Digital Services Act, platforms are obliged to remove illegal content once they become aware of it or otherwise risk becoming liable for it. The largest platforms have further obligations to assess and mitigate a set of systemic risks arising from how they are designed and used. They include actual or foreseeable negative outcomes for civic discourse and electoral integrity. The risk assessment and mitigation obligations have been further specified with a set of guidelines for platforms in times of elections. New rules for online platforms mean those that show political advertisements must have clear labelling showing who paid, what targeting techniques have been used and specifying the election issue to which the advertisement relates. Platforms that do not allow political advertisements must enforce this restriction proportionately and consistently.</p>
          <p eId="para_27"> To ensure audiences are exposed to a variety of voices, views and opinions, broadcasters are obliged to make sure news and current affairs output is presented in an objective and impartial manner without any expression of the broadcaster's own political views. However, there are currently no corresponding obligations that apply to content feeds on social media or the output of AI chatbots.</p>
          <p eId="para_28">Different types of digital media now rival traditional media for influence and we consider that the time has come to consider how similar plurality obligations could apply to new media. </p>
          <p eId="para_29"> Regulation is not the only tool for mitigating the risks that AI poses to civic discourse. At Coimisiún na Meán, we also oversee a host of media literacy initiatives to ensure that people can critically engage with and understand the media they consume, regardless of whether it is on TV, radio or online or generated by humans or AI. We want people to be aware of trusted sources of information and how to find them so that they can recognise fact from fiction. It is not our role to tell people what to think or say; our role is to ensure that they have agency to make up their own minds, free of manipulation or deception. There are other public bodies with important roles to play here, for example An Coimisiún Toghcháin, which has a role in providing electoral process information, ensuring that people can exercise their democratic rights. We also have journalism schemes, which are an important way to ensure there are trusted sources of information on matters such as local democracy. </p>
          <p eId="para_30"> In summary, at Coimisiún na Meán, we want to use the tools at our disposal to ensure that the deployment and use of AI systems benefits people, while ensuring that any negative impacts are effectively addressed through regulating and supporting the development of a healthy media landscape. As the impact of AI becomes clearer over time, there may need to be an assessment of whether other rules need to be updated to reflect changing consumer media consumption patterns and habits arising. I am happy to answer any questions committee members may have. </p>
        </speech>
        <speech by="#" eId="spk_5">
          <from> Professor Muiris MacCarthaigh<recordedTime time="2025-11-18T11:15:00+00:00"/></from>
          <p eId="para_31">I am speaking on behalf of Dr. Deepak Padmanabhan and myself, although I do not think that gives me eight minutes.</p>
          <p eId="para_32"><b><i>
							</i></b>My first point concerns the general use of AI in government. With the widespread popularity and rapid penetration of AI into contemporary social and economic life, governments have come under significant public pressure to incorporate AI into their operations. This is on the basis that AI will bring efficiency and productivity to activities and bring new insights to bear on policy problems, while also enhancing the capacity for objective and data-driven decision-making. A report in September by the OECD on the use of AI by governments internationally identified many risks but also noted the risk of not engaging with AI to yield benefits and develop capacities. </p>
          <p eId="para_33"> Although there is greater recognition of the different types of AI, that is, symbolic, deep learning and generative, AI is primarily a data-driven technology that operates by distilling patterns from large historical datasets into decisions. This implicitly encodes a decision-making paradigm underpinned by historical records, one that seeks to ensure continuity and consistency. These attributes make it more appropriate for some policy sectors than others. In sectors with a volatile policy context, such as policing, trade or immigration, the logic of AI may not be as applicable when compared to sectors such as education, health or housing. </p>
          <p eId="para_34"> An uncritical or inappropriate adoption of AI across government may precipitate unintended, undesirable or even harmful consequences. The adoption of AI should be informed by a careful consideration of the trade-offs between reliance on historic decision-making patterns and sensitivity to the concrete circumstances around individual decisions. </p>
          <p eId="para_35"> On AI leading to changing modes of decision-making and accountability in government, major advances in the scale and pace of government operations during the 20th and into the 21st century were, in general, transparent and subject to public accountability mechanisms. AI stands in contrast to this as it offers recommendations based on complex data patterns, with the underpinning logic of the recommendation being more opaque than transparent. This presents obvious challenges for the role of public servants, especially as ever more consequential decisions are subject to AI-informed considerations. Public servants may find themselves having to explain why they do not agree with an AI recommendation and there is the danger that the pathway of least resistance is to uncritically accept AI-generated decisions. </p>
          <p eId="para_36"> It is important to recall that the design of AI has emerged from the corporate sector. With the market economy being driven by logics of utilitarianism, that is, the greatest good for the greatest number, rather than concerns about democratic inclusion, AI technologies embed the utilitarian calculus in their operation. For example, the training process of deep neural networks seeks to minimise average error, which is a paradigm that does nothing to prevent a small number of cases from being heavily disadvantaged. </p>
          <p eId="para_37"> The opacity of AI-based decision making also poses some fundamental problems for democratic accountability. The Government, and by extension public services, are accountable to Parliament and the people at large. </p>
          <p eId="para_38">This encompasses the ability to ensure that each decision and the process of how the decision was arrived at hold up to public scrutiny. Different forms of AI present different challenges, but, essentially, there are issues concerning how information is generated and used.</p>
          <p eId="para_39"> As the committee will be well aware, ensuring effective regulation of AI is a challenge faced by most governments, not least because large technology companies have global presence which makes jurisdiction-specific regulation hard to institute and enforce. The EU has pioneered legislation, such as the GDPR and the AI Act, that has significant implications, but these remain only preliminary steps towards ensuring that AI serves the public good. Efforts towards AI regulation ought to include transparency mandates for usage within critical sectors so that key decisions remain amenable to scrutiny, challenge and rectification, as necessary. The influence that AI firms wield presents a lopsided power equation where citizens may feel caught in a binary, finding themselves caught between using AI subject to terms they may not find acceptable or not using it at all. Governments around the world have found it difficult to hold AI firms to account. Such is the pace of change that it has been a case of catching up rather than setting the regulatory frameworks and democratic guardrails within which AI must operate. We therefore really welcome the work of this committee and thank it for the opportunity to speak.</p>
        </speech>
        <speech by="#" eId="spk_6">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T11:20:00+00:00"/></from>
          <p eId="para_40">I thank the committee for the invitation to participate. AI is both a set of technologies, such as neural networks and transformer models, and a range of rhetorical claims. The technology and the claims are only loosely connected. I will argue that AI undermines the ideals of truth and democracy.</p>
          <p eId="para_41"> AI has an adversarial relation with the truth. As has been referred to, the core of its calculations are correlations not causal relations, so its outputs are plausible rather than factual. Google's Sundar Pichai was in the news this morning, backing me up on that point. I would describe AI’s pattern recognition as a form of computational conspiracy theory, and its outputs are disinformation even when they appear to be accurate. AI’s internal opacity and its inability to parse social complexity make it impossible to remove errors and bias. While a belief in AI’s superior powers persists, its claims to truth will retain authority while harming some of the most marginalised, which has also been mentioned. Even the engineers who build AI cannot explain what is going on inside to produce a particular result, so reliable regulation on that front is a non-starter. At the same time, the efforts to make AI more reliable actually make it more effective at selecting preferred versions of truth. The claims we hear that AI will solve everything from climate change to infectious disease deflect attention from the actual uncomfortable truths of our current moment. This hubris is driving an investment bubble, which Mr. Pichai also mentioned, that diverts vast sums from real social needs.</p>
          <p eId="para_42"> On democracy, it is increasingly clear that AI is precaritising rather than productive. It cannot really replace people but it can make their circumstances more vulnerable. AI is, in fact, extending forms of austerity prevalent since the crash of 2008 while preparing a new financial crash of its own. These conditions are corrosive to democracy. AI is also anti-democratic in terms of institutional and regulatory capture. We are currently seeing the EU walking back the flagship AI Act in the face of pressure from Trump and big tech. Peter Thiel, the founder of Palantir and patron of J.D. Vance, is currently on a lecture tour saying attempts to regulate AI are the work of the Antichrist. Meanwhile, the example of DOGE demonstrated AI’s effectiveness as a form of authoritarian cyberattack on centralised institutions. More broadly, AI is toxic to democracy via its impact on education and young people, as our colleague from the Electoral Commission will know. Large language models are sold as learning accelerators but actually substitute slop for critical thinking. Unfortunately, they are becoming young people's first port of call for everything from essays to relationship advice. In this context, AI undermines the replenishment of a citizenry with the capacity for independent thought. In its systemic effects, AI will fail to solve problems, cause collateral damage and benefit reactionary politics.</p>
          <p eId="para_43"> I have titled the next section of my submission "Recommendations", but these are really just tentative suggestions. I suggest that the committee avoid misleading responses to this state of affairs, such as the idea of AI sovereignty.</p>
          <p eId="para_44">AI should be considered harmful to whatever polity is hosting it. I suggest that the committee should at least be clear with itself what it is endorsing when it endorses AI. At best, the alleged benefits to healthcare or education really amount to algorithmic Thatcherism. A more likely outcome is that widespread AI adoption will strengthen the far right. I encourage the committee to see AI as a symptom rather than a cause and to use it as a diagnostic for the underlying problems of a system that needs some restructuring for the benefit of people and planet. Having said that, AI is an actor in its own right and one that will intensify real world problems like energy costs, unemployment and militarisation. Therefore, I also encourage the committee to place worker and community collectives at the heart of decision-making about AI, with a clear power of veto. This should also apply to the expanding number and scale of energy-hungry and recolonising data centres. Decision-making around AI should prioritise alternative solutions that reduce the overall dependence on computation and elevate direct social relationships.</p>
          <p eId="para_45"> I thank the committee and I am happy to participate in questions and answers.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_7">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T11:25:00+00:00"/></from>
          <p eId="para_46">I thank all of our witnesses for their work generally and for their insightful contributions here today. Members now have seven minutes for both questions and answers. I would like it if people could try to stick to that. The first is Deputy Naoise Ó Cearúil.</p>
        </speech>
        <speech by="#NaoiseOCearuil" eId="spk_8">
          <from>Deputy Naoise Ó Cearúil<recordedTime time="2025-11-18T11:25:00+00:00"/></from>
          <p eId="para_47">Go raibh maith agat, a Chathaoirligh. I am chairing another committee at the same time, so I apologise for missing the first opening statement. I read it with interest over the weekend. I use AI a lot for research purposes. Everything I do from a research perspective is always double-checked to ensure that the sources are correct.</p>
          <p eId="para_48"> Did An Coimisiún Toghcháin use AI in helping to draft this opening statement? The answer is "No". From reading it, some things stand out to me, particularly the use of the long em dashes that we would see in the likes of ChatGPT and Gemini and the language that is used. Since the answer is "No", that is fine. The reason I asked that question is I feel that there are no solutions or actions in the opening statement, particularly in light of what Mr. O'Leary called out in the presidential election of President Catherine Connolly. What actions did An Coimisiún Toghcháin take? What actions could it take in future?</p>
          <p eId="para_49"> That leads into a question as well about possibly establishing an AI and digital resilience unit, either within An Coimisiún Toghcháin or within the Department of local government and housing, to help tackle this type of particular misinformation and, let us be straight about it, election interference. Does Mr. O'Leary wish to answer these questions straight away?</p>
        </speech>
        <speech by="#" eId="spk_9">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T11:25:00+00:00"/></from>
          <p eId="para_50">Yes. I thank the Deputy. He will be aware that An Coimisiún Toghcháin has no regulatory authority. We have no investigative ability or sanctioning authority. It was originally envisaged in Part 5 of the Electoral Reform Act 2022 that we would have a role to play here, but that has been overtaken by EU legislation, etc. I understand that the Government intends to bring forward new legislation to deal with this. We used our information and education powers to take action on this. This particular deepfake came to our attention at about 10.30 p.m. one evening. We used our special channels with the platforms - the priority whitelist channels - to engage with them, which we did before midnight. By the time anybody got out of bed the following morning, that account was suspended. There were issues around that. The Streisand effect is very important. We all recognise that that happens-----</p>
        </speech>
        <speech by="#NaoiseOCearuil" eId="spk_10">
          <from>Deputy Naoise Ó Cearúil<recordedTime time="2025-11-18T11:25:00+00:00"/></from>
          <p eId="para_51">I am sorry to cut across Mr. O'Leary. I am just conscious of time. The damage was already done. I am not blaming An Coimisiún Toghcháin or anything like that. It took action as quickly as possible and used the channels it had to act. Does Mr. O'Leary think that, if An Coimisiún Toghcháin had additional regulatory powers, it would be able to get ahead of videos like this - I appreciate that it is impossible to get ahead of a lot of videos like this - and take more immediate action and have sanctions on the likes of Meta, X and different social media platforms in particular where these are being shared?</p>
        </speech>
        <speech by="#" eId="spk_11">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T11:30:00+00:00"/></from>
          <p eId="para_52">It is hard to get ahead of it because we do not know where it is coming from and there are so many. It is like whack-a-mole. They pop up all over the Internet. We are a brand-new organisation. We are trying to create a responsive, creative, innovative and versatile organisation. These are not often words that State bodies are accused of, so we are probably a little unusual in that regard. I am quite happy with the speed of our response. We caught it within minutes of it appearing online, courtesy of my colleague Mr. Callan. The system worked with Meta. Our relationship with the platforms tends to be reasonably good, but there are some actors that are less willing.</p>
        </speech>
        <speech by="#NaoiseOCearuil" eId="spk_12">
          <from>Deputy Naoise Ó Cearúil<recordedTime time="2025-11-18T11:30:00+00:00"/></from>
          <p eId="para_53">That is fine. To the credit of the staff, they acted very quickly. I commend them on that. What I am getting to is whether additional powers are required. Will the national AI office have the appropriate regulatory powers when it is established?</p>
          <p eId="para_54"> I will move on to Professor MacCarthaigh and Dr. Padmanabhan. Having read through and listened to their opening statements, I am interested in discovering whether Ireland could develop sector-specific AI roadmaps with built in accountability frameworks. I refer, for example, to mandatory algorithmic impact assessments for areas like health and housing.</p>
        </speech>
        <speech by="#" eId="spk_13">
          <from> Professor Muiris MacCarthaigh<recordedTime time="2025-11-18T11:30:00+00:00"/></from>
          <p eId="para_55">The whole point is that it is happening so quickly, as Mr. O'Leary mentioned. It is great to see this committee getting into greater awareness of the different sensitivities in different policy sectors. In the area of decision-making, AI is changing the nature of public service work, what public servants do and how they think about information. Even if they are not using it formally in work maybe they are using it at home to help their thinking. It would be a very good day's work for sure to think about the intensity of risk, for want of a better term, in different policy areas.</p>
        </speech>
        <speech by="#NaoiseOCearuil" eId="spk_14">
          <from>Deputy Naoise Ó Cearúil<recordedTime time="2025-11-18T11:30:00+00:00"/></from>
          <p eId="para_56">Yes.</p>
        </speech>
        <speech by="#" eId="spk_15">
          <from> Professor Muiris MacCarthaigh<recordedTime time="2025-11-18T11:30:00+00:00"/></from>
          <p eId="para_57">In the context of health, AI is fantastic for analysis of MRI scans and that sort of stuff.</p>
        </speech>
        <speech by="#NaoiseOCearuil" eId="spk_16">
          <from>Deputy Naoise Ó Cearúil<recordedTime time="2025-11-18T11:30:00+00:00"/></from>
          <p eId="para_58">Yes.</p>
        </speech>
        <speech by="#" eId="spk_17">
          <from> Professor Muiris MacCarthaigh<recordedTime time="2025-11-18T11:30:00+00:00"/></from>
          <p eId="para_59">However, the potential for misuse is extraordinary.</p>
        </speech>
        <speech by="#NaoiseOCearuil" eId="spk_18">
          <from>Deputy Naoise Ó Cearúil<recordedTime time="2025-11-18T11:30:00+00:00"/></from>
          <p eId="para_60">I will move on to transparency mechanisms. I do see the benefits of various Departments and, I suppose, the State utilising AI for efficiency gains, particularly as we see so much inefficiency in the system and systems. Does Professor MacCarthaigh think a central registry of Government AI systems, from which public summarised data would be available, would be beneficial to ensure that there is transparency and that people know something is being used to help compile reports or whatever or that a particular system is being used to help improve waiting times for particular types of surgery?</p>
        </speech>
        <speech by="#" eId="spk_19">
          <from> Dr. Deepak Padmanabhan<recordedTime time="2025-11-18T11:30:00+00:00"/></from>
          <p eId="para_61">One of the things about transparency and the transparency debate in general relates to whether you want to be transparent about the use of AI or whether you want to be transparent about the process in general. If you use-----</p>
        </speech>
        <speech by="#NaoiseOCearuil" eId="spk_20">
          <from>Deputy Naoise Ó Cearúil<recordedTime time="2025-11-18T11:30:00+00:00"/></from>
          <p eId="para_62">The output is key here. Transparency regarding output is what people really want to know about.</p>
        </speech>
        <speech by="#" eId="spk_21">
          <from> Dr. Deepak Padmanabhan<recordedTime time="2025-11-18T11:30:00+00:00"/></from>
          <p eId="para_63">Yes. The process of transformation from the input to the output. If you use AI, some parts of it are necessarily obscured because there is AI in there, and AI uses a lot of complex information processing. AI sits in a very uneasy relationship with transparency because even if you are transparent about the fact that you use a particular AI tool, that does not take you to the next level of understanding as to how things are happening underneath that.</p>
        </speech>
        <speech by="#NaoiseOCearuil" eId="spk_22">
          <from>Deputy Naoise Ó Cearúil<recordedTime time="2025-11-18T11:30:00+00:00"/></from>
          <p eId="para_64">I note Dr. McQuillan's scepticism. It is a light word to use in relation to artificial intelligence. What is his suggestion? There is no way of pausing or putting a stop to AI. Is he saying that the institutions of the State and Government should not engage with AI in any way, shape or form?</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_23">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T11:30:00+00:00"/></from>
          <p eId="para_65">Dr. McQuillan's reply should be succinct in light of the time constraints.</p>
        </speech>
        <speech by="#" eId="spk_24">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T11:30:00+00:00"/></from>
          <p eId="para_66">The narrative of inevitability itself should be questioned. This is essentially part of the sales pitch. Since AI is already very pervasive, as much caution as possible should be exercised. I would definitely recommend having a plan B.</p>
        </speech>
        <speech by="#NaoiseOCearuil" eId="spk_25">
          <from>Deputy Naoise Ó Cearúil<recordedTime time="2025-11-18T11:30:00+00:00"/></from>
          <p eId="para_67">What would that be?</p>
        </speech>
        <speech by="#" eId="spk_26">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T11:30:00+00:00"/></from>
          <p eId="para_68">I would not have any mechanism rely solely on AI for some of the reasons that have already been mentioned. You are building an inherent opacity into something you constitutionally cannot rely on. Building in AI as the central part of any system you would consider as having a substantial effect on society is extremely unwise. The education system here, like that in the UK, is currently under attack from AI.</p>
          <p eId="para_69">Having a really solid plan for how things would work as much as possible without AI is sensible.</p>
        </speech>
        <speech by="#DarrenORourke" eId="spk_27">
          <from>Deputy Darren O'Rourke<recordedTime time="2025-11-18T11:35:00+00:00"/></from>
          <p eId="para_70">I thank all of the witnesses. I will start where Deputy Ó Cearúil finished with Dr. McQuillan. Dr. McQuillan made a point on an issue that has come up previously in our hearings about the voice of the public in relation to the development of AI and participation. He referenced worker and community collectives. Will he expand on what he means and envisages by that?</p>
        </speech>
        <speech by="#" eId="spk_28">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T11:35:00+00:00"/></from>
          <p eId="para_71">In the first instance, the organised collectives would be things like trade unions. However, I am really referring to a broader issue with AI, which comes down to things like MRI scans, which I mentioned. The experience in the field is that context is most important in most things, including a lot of medical processes that rely on things like scans. The contextual understanding of what is going on is most important. That applies to everything, from education to government activities. There is the idea that AI gains its power by claiming to be this universal answer. In fact, we find that every situation has specific things that make things work. They may not be things written down and eaten by an AI. They might not be transparent to technologies and are generally dependent on people. Without being long-winded, in any context the group of people who are the most essentially insightful in that context should have a say about how much AI is introduced in that situation, if at all.</p>
        </speech>
        <speech by="#DarrenORourke" eId="spk_29">
          <from>Deputy Darren O'Rourke<recordedTime time="2025-11-18T11:35:00+00:00"/></from>
          <p eId="para_72">I will pick up on a point made by some other speakers, namely, that it is hugely challenging for Ireland as a state to regulate this sector on its own. We all have an appreciation of the nature of the power and influence these massive corporations have. What is the ability of a state, or even the European Union, to shape how AI looks?</p>
        </speech>
        <speech by="#" eId="spk_30">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T11:35:00+00:00"/></from>
          <p eId="para_73">The point kind of follows on, in the sense that it is not going to be possible for central mechanisms like the EU to manage this situation. The question of trust came up. This would align with some of the earlier discussions at this committee about civil and human rights. Diffusing as much trust and responsibility as possible to the local context provides a necessary damming system for this overflow of AI, which could possibly not be placed by the centre simply because of its positioning, but also because of its vulnerability to these kinds of political pressures.</p>
        </speech>
        <speech by="#DarrenORourke" eId="spk_31">
          <from>Deputy Darren O'Rourke<recordedTime time="2025-11-18T11:35:00+00:00"/></from>
          <p eId="para_74">Mr. Godfrey made a point about plurality and obligations on the broadcast media to provide balance in electoral contests, and that this is something we should look at in the digital space. Will he expand on that point? There are also other areas like, for example, in the Digital Services Act. How might we apply that in Ireland and are there opportunities to strengthen regulation?</p>
        </speech>
        <speech by="#" eId="spk_32">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T11:35:00+00:00"/></from>
          <p eId="para_75">In terms of plurality, one of the things we see is that whole social media feeds - not individual posts but the whole feed - can start to be regarded as a media type in its own right. The reason we have historically had quite a lot of regulation of broadcasters is that broadcasting was the most influential media for influencing how people thought. A social media feed is not the same as a broadcast. The role of the platform is not the same. They are not the editor in the way that a broadcaster is, but they have a big role in selecting what is in the feed. For example, under the European Media Freedom Act, there is something called media privilege. Broadcasters or journalists who are regulated by an organisation like the Press Council have a privilege where, if it is intended to take down any of their content, they have to be given advance notice so they can challenge that in a way that ordinary people are not.</p>
          <p eId="para_76">One thing that might be done would be to extend that privilege so that the content that those trusted journalists post should be given prominence in people's feeds. At the moment, we get this phenomenon that the feeds are optimised for engagement. People talk about rage bait, so there is this echo chamber effect where people get a monolithic-----</p>
        </speech>
        <speech by="#DarrenORourke" eId="spk_33">
          <from>Deputy Darren O'Rourke<recordedTime time="2025-11-18T11:40:00+00:00"/></from>
          <p eId="para_77">On a related point, which I have highlighted here, there have been lots of discussion about recommender systems. There is legislation on the books here and there has been a lot of criticism concerning the weakness of the primary legislation or its application in Ireland. Is there a need or an opportunity to ensure that those recommender systems are switched off? Mr. Godfrey made a point about rage baiting and driving people down a rabbit hole, or whatever way one wants to put it. Recommender systems are a particular feature and AI has a particular role in them.</p>
        </speech>
        <speech by="#" eId="spk_34">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T11:40:00+00:00"/></from>
          <p eId="para_78">I think they need to be made safe, both for the individuals consuming the feeds and for society as a whole. People talk about turning them off by default but I think people would turn them back on again.</p>
        </speech>
        <speech by="#DarrenORourke" eId="spk_35">
          <from>Deputy Darren O'Rourke<recordedTime time="2025-11-18T11:40:00+00:00"/></from>
          <p eId="para_79">How do we make them safe? What would that look like?</p>
        </speech>
        <speech by="#" eId="spk_36">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T11:40:00+00:00"/></from>
          <p eId="para_80">For example, for children the recommender systems have addictive design features to keep people using them. Under the Digital Services Act, those have been identified and when platforms have children as their users, they are required not to have addictive design features and not to promote content that is unsuitable for children, such as pornography. I absolutely agree with the Deputy that we can look at recommender systems and see how can they be designed to make sure that when a feed contains material that is relevant to civic discourse, that material in the feed that gets recommended does not just put one point of view but puts a balanced point of view, that it contains trusted journalism and that the algorithm does not reflect the political preferences of the owners of the social media company, all of which would be analogous to the obligations we put on to broadcasters.</p>
        </speech>
        <speech by="#DeeRyan" eId="spk_37">
          <from>Senator Dee Ryan<recordedTime time="2025-11-18T11:40:00+00:00"/></from>
          <p eId="para_81">I thank all the witnesses for their opening statements and the discussion so far. It is really helpful to us and informative in the work that we are doing in examining this whole area. In my brain I am parsing the contributions and separating them. I am categorising Mr. O'Leary, Mr. Callan, Mr. Godfrey and Ms Pollock in my mind in terms of the democratic impact and the stuff that people think of more generally when they consider AI and the potential for deepfakes. I thank them for the very informative discussion we are having on recommender systems and Deputy O'Rourke's questions around that. I will continue with this topic for the moment. I am also interested in speaking to the other witnesses about the very valuable contribution and alarm bells being sounded about the potential for AI as a technology to be used and deployed across public services.</p>
          <p eId="para_82"> I will first address the democratic piece, and I ask Mr. O'Leary to forgive me because I should know more about the work of An Coimisiún Toghcháin. From a beginner's perspective, what does an coimisiún look at in terms of measuring electoral interference? Is that within its remit at present?</p>
        </speech>
        <speech by="#" eId="spk_38">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T11:40:00+00:00"/></from>
          <p eId="para_83">As I mentioned earlier, we do not have any regulatory authority here right now. It was envisaged in the legislation that established An Coimisiún Toghcháin that, under Part 5, we would have investigative and sanctioning powers. That Part was never commenced because of the advent of the Digital Services Act, the AI Act, etc. We use our education and information powers to intervene at a very soft level. These are soft powers that we use.</p>
        </speech>
        <speech by="#DeeRyan" eId="spk_39">
          <from>Senator Dee Ryan<recordedTime time="2025-11-18T11:40:00+00:00"/></from>
          <p eId="para_84">I have seen some of An Coimisiún Toghcháin's very good work in terms of questionnaires and surveys post election. There were questions in those around how many candidates the respondent met in person.</p>
        </speech>
        <speech by="#" eId="spk_40">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T11:40:00+00:00"/></from>
          <p eId="para_85">Yes.</p>
        </speech>
        <speech by="#DeeRyan" eId="spk_41">
          <from>Senator Dee Ryan<recordedTime time="2025-11-18T11:45:00+00:00"/></from>
          <p eId="para_86">Does an coimisiún include any questions at the moment around where people are informed or where people get information?</p>
        </speech>
        <speech by="#" eId="spk_42">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T11:45:00+00:00"/></from>
          <p eId="para_87">There is a whole section on that about where people get the information on which they base their decisions on where to vote. There are trusted sources of information. On one end of the spectrum, it tends to be RTÉ, as the national broadcaster, and the mainstream media and on the other end, social media, such as WhatsApp and so forth.</p>
        </speech>
        <speech by="#DeeRyan" eId="spk_43">
          <from>Senator Dee Ryan<recordedTime time="2025-11-18T11:45:00+00:00"/></from>
          <p eId="para_88">I apologise if I am cutting across Mr. O'Leary; it is in the interest of time. An coimisiún does, therefore, measure how many people are getting information from social media platforms.</p>
        </speech>
        <speech by="#" eId="spk_44">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T11:45:00+00:00"/></from>
          <p eId="para_89">Indeed.</p>
        </speech>
        <speech by="#DeeRyan" eId="spk_45">
          <from>Senator Dee Ryan<recordedTime time="2025-11-18T11:45:00+00:00"/></from>
          <p eId="para_90">What communications and crossover would there be between Mr. O'Leary and Mr. Godfrey? Are there currently any interactions between their two organisations?</p>
        </speech>
        <speech by="#" eId="spk_46">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T11:45:00+00:00"/></from>
          <p eId="para_91">Yes, our functions overlap significantly in this electoral integrity space. We speak to Coimisiún na Meán all the time and at all levels within the organisation. There is potential for greater collaboration in the future, certainly.</p>
        </speech>
        <speech by="#DeeRyan" eId="spk_47">
          <from>Senator Dee Ryan<recordedTime time="2025-11-18T11:45:00+00:00"/></from>
          <p eId="para_92">With regard to the example of the deepfake of President Connolly, will Mr. O'Leary talk us through how that came to an coimisiun's attention and then the interaction between their organisations?</p>
        </speech>
        <speech by="#" eId="spk_48">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T11:45:00+00:00"/></from>
          <p eId="para_93">We used our individual responsibility because speed was of the essence. Mr. Callan surfaced this video at 10.30 p.m. and then we had an online meeting with the senior team and decided to push the button to use our whitelist with Meta to ask it to take it down. We did that just before midnight. By the time anybody got up in the morning, the account had been suspended. The system in that case worked, but there were remnants of the video. There were legacy videos all over the web, which took days-----</p>
        </speech>
        <speech by="#DeeRyan" eId="spk_49">
          <from>Senator Dee Ryan<recordedTime time="2025-11-18T11:45:00+00:00"/></from>
          <p eId="para_94">Yes, on WhatsApp and everything. How did it come to Mr. Callan's attention?</p>
        </speech>
        <speech by="#" eId="spk_50">
          <from> Mr. Nick Callan<recordedTime time="2025-11-18T11:45:00+00:00"/></from>
          <p eId="para_95">It was the night of the "Prime Time" debate, so a lot of us who were in this space were probably engaged with watching that. After that, I would casually be browsing social media for presidential election-related material. I think I saw it on LinkedIn first, and LinkedIn referenced the Meta origin of it. I brought it to the attention of the senior team after that.</p>
        </speech>
        <speech by="#DeeRyan" eId="spk_51">
          <from>Senator Dee Ryan<recordedTime time="2025-11-18T11:45:00+00:00"/></from>
          <p eId="para_96">Well done. When did Mr. Godfrey's organisation intersect and what actions did it take?</p>
        </speech>
        <speech by="#" eId="spk_52">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T11:45:00+00:00"/></from>
          <p eId="para_97">I might just take a step back to the relationship between us and An Coimisiún Toghcháin. The regulatory regime that applies is the Digital Services Act in this case. Under that Act, companies like Meta - the large platforms - have obligations to identify and mitigate risks to electoral integrity. There is a whole set of guidelines about what they are expected to do, and in the case of deepfakes, when they come to their attention, they are expected to either take them down or at least label them as deepfakes. One of the things we do is, before an electoral event like the presidential election, we run a round table with the platforms, An Coimisiún Toghcháin, An Garda Síochána and other people to make sure everybody is ready to play their role. When this came to our attention, therefore, we were also in touch with the platforms. Our role is not to ask for it to be taken down. Our role is to understand whether the platforms had acted in an appropriate manner. We are still evaluating that. We will be doing our own evaluation of the election and providing that to the European Commission because it is the body with the enforcement responsibility in this regard.</p>
        </speech>
        <speech by="#DeeRyan" eId="spk_53">
          <from>Senator Dee Ryan<recordedTime time="2025-11-18T11:45:00+00:00"/></from>
          <p eId="para_98">This is just an observation. It strikes me as particularly difficult for An Coimisiún Toghcháin to act as a safeguard for us in this area when we do not recognise the social media platforms as broadcasters and we do not recognise that they have editorial control over content, which I would argue they are and they do. I found Mr. Godfrey's comments that An Coimisiún na Meán is keeping a watching brief on this very interesting. As we move into this area where AI is more prevalent and the recommender systems are making those decisions as to what our citizens should see, it is even more important that we hold the broadcasters responsible for content, such as RTÉ, or legacy media as it is referred to and trusted media as we find it, accountable for what they publish and amplify. In my view, we are perhaps already there as to whether we should be regarding platforms in the same way.</p>
        </speech>
        <speech by="#" eId="spk_54">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T11:50:00+00:00"/></from>
          <p eId="para_99">I absolutely agree with the Senator that platforms need to take responsibility for the consequences of the choices they make in the design of their recommender systems. Also, they lose their exemption from liability once they have actual knowledge. Once An Coimisiún Toghcháin told them about this, they had then lost any exemption from liability. Under the AI Act provision, which is not yet enforceable, there is an obligation to label deepfake content. Once they know there is unlabelled deep-fake content on their platform, if they allow that to stay, they would then be in breach of the AI Act. That is not until sometime next year, but we will have a responsibility or a function involved in enforcing that. There was an earlier question asking what more was needed. That would be a very useful tool for addressing deepfakes. They are always addressed after they are spotted. It is very hard to stop them being there in the first place. </p>
        </speech>
        <speech by="#JamesGeogheganFG" eId="spk_55">
          <from>Deputy James Geoghegan<recordedTime time="2025-11-18T11:50:00+00:00"/></from>
          <p eId="para_100">It is hard to confine this conversation just to AI because it touches on everything. I hope the witnesses will indulge me in the beginning. Mr. O'Leary mentioned in his statement that generally there is trust in our democracy and in the institutions of our democracy and our elections. Did the inclusion of a candidate who had pulled out of the presidential election race on people's ballot paper pose a delegitimisation or threat to our democracy or a risk to people's confidence in the electoral system in a way that, perhaps, no other event in our electoral history had?</p>
        </speech>
        <speech by="#" eId="spk_56">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T11:50:00+00:00"/></from>
          <p eId="para_101">It certainly posed a communications challenge. I went out and did a number of explainer videos explaining the legislative position and why a candidate remained on the ballot paper when he indicated he had withdrawn. In essence, because of the way the law is, if someone does not withdraw before the close of nominations then they cannot withdraw from the presidential election. They can stop campaigning, of course. The explainer videos went some way to increasing people's understanding of what happened. The viewership for those videos was enormous. I think it helped. There was still confusion on polling day, there is no doubt about that. </p>
        </speech>
        <speech by="#JamesGeogheganFG" eId="spk_57">
          <from>Deputy James Geoghegan<recordedTime time="2025-11-18T11:50:00+00:00"/></from>
          <p eId="para_102">There was some reporting at the time that there had been eleventh hour discussions that Mr. O'Leary or the Electoral Commission were involved in, on whether the law said what it said. However, there was no ambiguity with the law. Could Mr. O'Leary elaborate on that period? Was there any uncertainty? Once the decision was taken, was the Electoral Commission fairly legally certain or was there a period of doubt? Did it seek external advice? What took place?</p>
        </speech>
        <speech by="#" eId="spk_58">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T11:50:00+00:00"/></from>
          <p eId="para_103">The law is clear in relation to this. There was no doubt in our mind. The Minister for housing does have powers. It is called a special difficulty order, where the Minister can intervene as unforeseen events arise. I did have a conversation with the Minister and he was not inclined to make a special difficulty order in this instance, so the law was clear, the law stood, and we went on and made the explainer videos. </p>
        </speech>
        <speech by="#JamesGeogheganFG" eId="spk_59">
          <from>Deputy James Geoghegan<recordedTime time="2025-11-18T11:50:00+00:00"/></from>
          <p eId="para_104">Had the Minister made a special difficulty order at that time, legally could the candidate's name have been removed from the ballot paper?</p>
        </speech>
        <speech by="#" eId="spk_60">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T11:50:00+00:00"/></from>
          <p eId="para_105">Yes, in theory. The difficulty was that postal ballots had already been posted. People had ballots with the third candidate on them already and all the other ballot papers had been printed. It would have involved pulping all the ballot papers, reprinting them, and cancelling and reissuing postal ballots. That was not going to-----</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_61">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T11:50:00+00:00"/></from>
          <p eId="para_106">I am allowing the Deputy some indulgence.</p>
        </speech>
        <speech by="#JamesGeogheganFG" eId="spk_62">
          <from>Deputy James Geoghegan<recordedTime time="2025-11-18T11:50:00+00:00"/></from>
          <p eId="para_107">I am going to move on, but just back to my original statement regarding trust and democracy, arising from all of this, does Mr. O'Leary think changes are necessary with respect to the laws, deadlines and the nomination of candidates? Are there things which it is now necessary to change to ensure the type of scenario which took place in the election does not re-emerge?</p>
        </speech>
        <speech by="#" eId="spk_63">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T11:50:00+00:00"/></from>
          <p eId="para_108">There will always have to be a deadline. There will always have to be a cut-off date after which somebody cannot withdraw. If candidates withdraw two or three days before polling day, what happens then? The law is clear right now that the closing date for nominations is the closing date. We will have data on trust in the electoral process in about a month.</p>
          <p eId="para_109">Our national election and democracy study survey will be available sometime next month and we will have a clearer idea of whether this particular issue had an impact on people's trust in the process.</p>
        </speech>
        <speech by="#JamesGeogheganFG" eId="spk_64">
          <from>Deputy James Geoghegan<recordedTime time="2025-11-18T11:55:00+00:00"/></from>
          <p eId="para_110">Sticking with the theme of trust and impartiality-----</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_65">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T11:55:00+00:00"/></from>
          <p eId="para_111">And AI.</p>
        </speech>
        <speech by="#JamesGeogheganFG" eId="spk_66">
          <from>Deputy James Geoghegan<recordedTime time="2025-11-18T11:55:00+00:00"/></from>
          <p eId="para_112">-----and AI. It is all connected to Coimisiún na Meán. The commission is not able to look into what a public broadcaster's social media accounts do in terms of reframing or repurposing things that have been on the radio or the television, is it?</p>
        </speech>
        <speech by="#" eId="spk_67">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T11:55:00+00:00"/></from>
          <p eId="para_113">No. I believe it is planned to have our code on fairness, objectivity and impartiality cover the contents of public broadcasters' social media accounts under the broadcasting (amendment) Bill.</p>
        </speech>
        <speech by="#JamesGeogheganFG" eId="spk_68">
          <from>Deputy James Geoghegan<recordedTime time="2025-11-18T11:55:00+00:00"/></from>
          <p eId="para_114">Is there anything stopping broadcasters that have licences to operate as public broadcasters now? Why do they have to wait for the law? There is a clear risk here that a public broadcaster might run a perfectly fair programme as a public broadcast but then slice and dice that for social media. It then goes through the algorithms, some of them AI-driven. That reproduction may possibly get more viewers or listeners and yet everything is perfectly in line with public broadcasting regulations. However, if it was on the TV or the radio, it might be a serious breach. What is the commission seeing out there? Is it observing this? Does it have a view?</p>
        </speech>
        <speech by="#" eId="spk_69">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T11:55:00+00:00"/></from>
          <p eId="para_115">We are not seeing inconsistent editorial standards between what broadcasters put on their social media feeds and what they broadcast. It is important for them to retain trust. As I have said, we are a creature of statute. We can only regulate according to the powers we have. The point the Deputy makes will apply to RTÉ and TG4 as the State broadcasters. They will be bound in respect of their social media output. We talk about public service media as opposed to public service broadcasting. That is a recognition that the aims of what used to be public service broadcasting need to be reflected through all the channels open to those broadcasters, including their own players and their social media accounts. It is quite right that the obligations relating to news and current affairs should apply to those social media accounts.</p>
        </speech>
        <speech by="#JamesGeogheganFG" eId="spk_70">
          <from>Deputy James Geoghegan<recordedTime time="2025-11-18T11:55:00+00:00"/></from>
          <p eId="para_116">I only have 30 seconds left. We have talked a lot about social media companies, the debate as to whether they are publishers, and the content people get. We know all of the data as to where people from certain age cohorts access news. There is clearly a shift already taking place. People are accessing news from AI-driven aggregators on different platforms a lot more. Do the existing regulatory frameworks pierce the stuff that is coming through these AI platforms? That may be a question for the Electoral Commission and Coimisiún na Meán. Where are we in that space?</p>
        </speech>
        <speech by="#" eId="spk_71">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T11:55:00+00:00"/></from>
          <p eId="para_117">There has always been a need to balance freedom of expression with regulation. It has never been the case that there has been any State regulation of the output of print media. It has always been the case that there has been State regulation of the output of broadcast media. That has really been based on the influence different media have. It is quite clear from the work Mr. O'Leary has done on how people make up their minds in elections and the work we do with the Reuters news reports on people's sources of news that, as the Deputy has said, online sources are more significant sources of news for certain cohorts, particularly the younger cohorts, than traditional media. It is very early days for AI chatbots but we are reviewing our media plurality policy this year and next year and one of the things we are concerned about is looking at the role of chatbots as a source of news and what might be done about that. However, at the moment, there is no law that regulates the output of chatbots.</p>
        </speech>
        <speech by="#JamesGeogheganFG" eId="spk_72">
          <from>Deputy James Geoghegan<recordedTime time="2025-11-18T11:55:00+00:00"/></from>
          <p eId="para_118">From an electoral perspective, is this something that has been looked at?</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_73">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T11:55:00+00:00"/></from>
          <p eId="para_119">I will allow 30 seconds for an answer.</p>
        </speech>
        <speech by="#" eId="spk_74">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T11:55:00+00:00"/></from>
          <p eId="para_120">All of this is on the table for us right now. We have set up an AI committee within An Coimisiún Toghcháin to look at the challenges and opportunities AI presents because there may be some benefits to using AI in handling our workload.</p>
          <p eId="para_121">I mentioned the first pass we do at the constituency reviews. Time will be very short between the census and the next scheduled general election. We need to take advantage of technology in that regard to look at what-----</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_75">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:00:00+00:00"/></from>
          <p eId="para_122">I am quite certain a lot of people here will take an interest in that.</p>
        </speech>
        <speech by="#" eId="spk_76">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T12:00:00+00:00"/></from>
          <p eId="para_123">It is a question of balance between maths and geography. We want geography to win all the time but sometimes maths wins. That is a challenge for us.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_77">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:00:00+00:00"/></from>
          <p eId="para_124">I thank Mr. O'Leary. Deputy Geoghegan noted that the broadcasting amending legislation is before the media committee for pre-legislative scrutiny, which means some of those issues are likely to be debated soon. The next speaker is Deputy Gibney.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_78">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-11-18T12:00:00+00:00"/></from>
          <p eId="para_125">I apologise for not being able to attend the meeting room. I am just upstairs. I have some germs I did not want to share with everybody in the room. I am finding today's discussion absolutely fascinating.</p>
          <p eId="para_126"> My first question is for Dr. Godfrey. During the discussion earlier on the comparison between traditional media versus online media, he described how the influence of a media stream, for example, is perhaps not as prominent as that of opinion columns. Does he have data behind that statement? Is there a reason he considers it a valid claim? Depending on the audience, I would have thought people's feeds or streams are, in fact, much more influential. Will he elaborate on that particular point?</p>
        </speech>
        <speech by="#" eId="spk_79">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T12:00:00+00:00"/></from>
          <p eId="para_127">I am very flattered that the Deputy has awarded me a PhD but I am afraid it is quite undeserved.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_80">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-11-18T12:00:00+00:00"/></from>
          <p eId="para_128">My apologies.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_81">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:00:00+00:00"/></from>
          <p eId="para_129">We see the powers of this committee.</p>
        </speech>
        <speech by="#" eId="spk_82">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T12:00:00+00:00"/></from>
          <p eId="para_130">I will wear my robes next time. To clarify what I said, I absolutely agree that people's social media feeds are increasingly influential. The Reuters news reports we have show they are the primary source of news for some people, particularly the younger cohort. I understand An Coimisiún Toghcháin's research into how people make up their mind on how to vote also shows there are cohorts who are much more influenced by social media than by traditional media. The point I was making is that as the law stands, we have quite a lot of regulation of traditional broadcast media but we do not have anything corresponding for social media. We think the time has come to consider how best to apply what are called internal plurality obligations to social media feeds.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_83">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-11-18T12:00:00+00:00"/></from>
          <p eId="para_131">That is exactly the point I wanted clarified and I thank Mr. Godfrey for doing so. What I am hearing around the room is something I have been pushing quite a lot, which is to ask witnesses who come before us whether they believe platforms should be legally defined as publishers. I put that question now to Mr. Godfrey.</p>
        </speech>
        <speech by="#" eId="spk_84">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T12:00:00+00:00"/></from>
          <p eId="para_132">There is an awful lot of content on social media platforms. Making them responsible for all their content probably would be a step too far. Rather than taking it as a binary choice as to whether they should be publishers, the question I would ask is what responsibility they have in terms of the design of their recommender systems. It is much more the reach of the content that matters. If someone posts a deepfake and only one person sees it, that does not do much harm, but if that deepfake is amplified and shown to everybody, then it does cause harm.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_85">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-11-18T12:00:00+00:00"/></from>
          <p eId="para_133">The issue I have is that it then comes down to a principle. The reason we have trust in traditional media is that we know the principles of media integrity are upheld by them, albeit to varying degrees, I would argue, in terms of the plurality system that was mentioned and everything else. For me, it is about the principle, whereas if we try to parse it out and categorise in too many ways, it becomes problematic. However, I appreciate Mr. Godfrey's point.</p>
          <p eId="para_134"> What are his thoughts on the governance of AI within the State? Being at the helm of a new body, I am sure he has been observing the development of the AI office, as far as it has gone, and the network of bodies that will contribute to the governance of AI in the State. Is he confident that enough independence and resources have been directed towards the right places to do this in an appropriate way?</p>
        </speech>
        <speech by="#" eId="spk_86">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T12:00:00+00:00"/></from>
          <p eId="para_135">The proof of the pudding will be in the eating. It is right that there should be a variety of bodies involved.</p>
          <p eId="para_136">The competencies we will have will relate to the people we already regulate. It makes a lot of sense for the people who are experts and who already have enforcement and supervision functions to operate within their own sectors. We are in conversation with the relevant Departments about the resources we will need. That conversation has not yet concluded. A bit different from other areas, we will need some technical, IT and digital skills which have tended to be harder for the public sector to compete for. That may turn out to be an issue.</p>
          <p eId="para_137"> As well as resources, when the Bill comes to it for pre-legislative scrutiny, the committee might like to look at the enforcement powers, particularly investigative and information-gathering powers. The latter are essential in the context of a regulator being effective.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_87">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-11-18T12:05:00+00:00"/></from>
          <p eId="para_138">I welcome Mr. O'Leary. Can I put the same question to him? What are his thoughts on the development of governance of AI in the State?</p>
        </speech>
        <speech by="#" eId="spk_88">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T12:05:00+00:00"/></from>
          <p eId="para_139">We are one of the nine fundamental rights authorities under the AI Act. We have been designated. From August of next year, we will have some formal responsibilities. I would point to the same challenge that Mr. Godfrey just outlined.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_89">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-11-18T12:05:00+00:00"/></from>
          <p eId="para_140">I am sorry to interrupt. If I could go beyond what Mr. O'Leary is expecting and is being asked in respect of his own body, given that he for many years he has held senior roles across the Civil Service and understands the requirement for independence probably more than any other individual, particularly in the role he now has as leader of An Coimisiún Toghcháin, it is in that context I am asking if it is his observation that independence is being given in the way he would hope and expect.</p>
        </speech>
        <speech by="#" eId="spk_90">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T12:05:00+00:00"/></from>
          <p eId="para_141">Yes. We have had no difficulty exerting our independence in anything we have done so far. As a result, I would expect it will be the same in this regard.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_91">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-11-18T12:05:00+00:00"/></from>
          <p eId="para_142">I am specifically asking about the AI office, which is currently in development within the Department of enterprise. I have concerns around that. Although the ultimate expectation is that the AI office will pop out of the Department of enterprise, for me, having also been at the helm of an independent State agency, how it is founded and built at the outset really will inform how it goes forward for evermore. I have concerns that independence is not guaranteed as long as it is developed in a place where there absolutely are conflicts of interest. Does Mr. O'Leary have concerns around that?</p>
        </speech>
        <speech by="#" eId="spk_92">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T12:05:00+00:00"/></from>
          <p eId="para_143">I do not have any concerns right now. There are nine independent bodies which form the fundamental rights authorities here. When we think about the role of the DPC, IHREC, ourselves and Coimisiún na Meán, I do not foresee any difficulties in the context of any of these bodies being coerced or forced into doing something they feel is not right. Our experience so far, as an independent body which is basically set up under statute and which has emerged from the Department of housing, is that the Government and the Oireachtas have been more than willing to allow us to flex our independent muscles. We have all the facilities we need to do that.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_93">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-11-18T12:05:00+00:00"/></from>
          <p eId="para_144">I cannot see the clock. How much time do I have left?</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_94">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:05:00+00:00"/></from>
          <p eId="para_145">The Deputy is over time. If she has a very brief question, however, I will allow it.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_95">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-11-18T12:05:00+00:00"/></from>
          <p eId="para_146">That is fine. I will wait until the next round.</p>
        </speech>
        <speech by="#PaulMurphy" eId="spk_96">
          <from>Deputy Paul Murphy<recordedTime time="2025-11-18T12:05:00+00:00"/></from>
          <p eId="para_147">I will start with Mr. Godfrey. Can I ask why Coimisiún na Meán dropped the requirement for social media companies to turn off recommender algorithms? The requirement was in the draft online safety code published in December 2023. By the time the final version was published in May 2024, however, it was gone.</p>
        </speech>
        <speech by="#" eId="spk_97">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T12:05:00+00:00"/></from>
          <p eId="para_148">In the draft code, we did not actually have a recommendation to turn off recommender systems. What we had consulted on was the idea that we might have greater transparency about recommender systems.</p>
        </speech>
        <speech by="#PaulMurphy" eId="spk_98">
          <from>Deputy Paul Murphy<recordedTime time="2025-11-18T12:05:00+00:00"/></from>
          <p eId="para_149">The draft code referred to measures to ensure that "recommender algorithms based on profiling should be turned off by default."</p>
        </speech>
        <speech by="#" eId="spk_99">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T12:05:00+00:00"/></from>
          <p eId="para_150">By default, yes. We got feedback and looked at the interaction between the online safety code, the Online Safety and Media Regulation Act and the Digital Services Act. Essentially, the conclusion reached was that recommender systems were better dealt with under the Digital Services Act. That was a better legal basis for it.</p>
        </speech>
        <speech by="#PaulMurphy" eId="spk_100">
          <from>Deputy Paul Murphy<recordedTime time="2025-11-18T12:05:00+00:00"/></from>
          <p eId="para_151">Did that feedback come from big tech companies?</p>
        </speech>
        <speech by="#" eId="spk_101">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T12:05:00+00:00"/></from>
          <p eId="para_152">We had some feedback from big tech companies. We had feedback from NGOs and the European Commission. We also had extensive legal advice.</p>
        </speech>
        <speech by="#PaulMurphy" eId="spk_102">
          <from>Deputy Paul Murphy<recordedTime time="2025-11-18T12:10:00+00:00"/></from>
          <p eId="para_153">In the context of the feedback from the NGOs, there was a joint submission by 60 civil society groups which welcomed the inclusion of a call for recommender systems to be turned off by default. The feedback from the tech groups was that they were against that, as was that from the European Commission.</p>
        </speech>
        <speech by="#" eId="spk_103">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T12:10:00+00:00"/></from>
          <p eId="para_154">There were a lot of questions about the interaction between what can be done under the online safety code, which is there to implement the audiovisual media services directive, and under the DSA, which is a maximum harmonisation measure. The conclusion, as I say, was that in order to get the code in place through the TRIS process and avoid the prospect of having things struck down because they were inconsistent with the DSA, it was better to use the DSA as the mechanism for addressing recommender system issues.</p>
        </speech>
        <speech by="#PaulMurphy" eId="spk_104">
          <from>Deputy Paul Murphy<recordedTime time="2025-11-18T12:10:00+00:00"/></from>
          <p eId="para_155">The industry submission claimed that recommender systems play an important role in ensuring a safe, predictable and trusted online environment by making sure that users are connected to relevant and high-quality information. That goes strongly against the evidence the committee has heard so far in terms of people being pushed down far-right pipelines, anti-immigrant pipelines and eating disorder pipelines incredibly quickly after setting up blank social media accounts. Would Mr. Godfrey agree with that claim from the industry?</p>
        </speech>
        <speech by="#" eId="spk_105">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T12:10:00+00:00"/></from>
          <p eId="para_156">The Deputy is quite right in that the way recommender systems work can have very negative effects on users, particularly children. As stated earlier, there are now much more extensive guidelines about how recommender systems intended for situations where children need to use them must be configured to meet the obligation to keep children safe online under Article 28 of the DSA. As a result, it is important that we make those things happen. Recommender systems do have some utility for users. When they are configured with the sole aim of maximising engagement, they do not keep users safe. As we have seen, they promote rage bait and echo chambers. In addition, the content that users engage with and are attracted by is not necessarily healthy.</p>
        </speech>
        <speech by="#PaulMurphy" eId="spk_106">
          <from>Deputy Paul Murphy<recordedTime time="2025-11-18T12:10:00+00:00"/></from>
          <p eId="para_157">I thank Mr. Godfrey. I also thank Dr. McQuillan for his blunt assessment of the problems with AI. It is a necessary part of the conversation and an important contribution. He stated, "We are currently seeing the EU walking back the flagship AI Act in the face of pressure from Trump and big tech.” Will he expand on that a little?</p>
        </speech>
        <speech by="#" eId="spk_107">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T12:10:00+00:00"/></from>
          <p eId="para_158">At the moment, the leaked propositions are actually to walk back both the AI Act and some of the GDPR. This is not stated in the leaked proposals, but, presumably, it is happening under pressure from big tech and most directly from the Trump Administration. We know how closely they work in co-ordination with each other.</p>
          <p eId="para_159"> If I may try to bridge between that issue and some of the conversations around social media and the question of AI and the state, which, I understood from the Chair, was also the core issue of the committee's work, it is very interesting to hear about social media, disinformation and the influence of the platforms, because these are exactly the same issues that are before the committee in terms of AI. You have the corporate presence and power, which, to some extent is already beyond regulation and demonstrates that repeatedly but, more fundamentally - and this is in relation to the technology itself - they have a form of technology, the AI algorithmic systems, which is essentially going to introduce deep fakes and ranking systems of a certain character and type into the very functioning of the state. Therefore, it seems that when it comes to the issues that are now being reflected, the proof of the pudding is in the eating. People have eaten it in terms of social media, and the question is whether they are going to eat it in terms of the rest of the systems they are in. This is going to introduce the stuff into the very systems themselves. Not only that, it is going to be done by shovelling a lot of public money at it at a time when the companies are talking about the fact that the whole AI industry is greatly overvalued. This is going to be done at considerable cost in the context of climate impacts.</p>
        </speech>
        <speech by="#PaulMurphy" eId="spk_108">
          <from>Deputy Paul Murphy<recordedTime time="2025-11-18T12:10:00+00:00"/></from>
          <p eId="para_160">I thank Dr. McQuillan. I was struck by his point that large language models are sold as learning accelerators but that they substitute slop for critical thinking. These models are becoming the first port of call for everything from essays to relationship advice. There are now ads visible across Dublin city - and, presumably, across the country - for ChatGPT that show a couple standing beside a car that is clearly broken down and who are supposedly using ChatGPT to try to fix it.</p>
          <p eId="para_161">I do not know if it is legally responsible if they get the wrong hallucination and blow themselves up or whatever. There was a piece on the radio yesterday where a columnist was speaking about how she uses ChatGPT or some AI or LLM for medical advice. There was a doctor in the studio. I missed the doctor as I had got home by then, but I presume they were horrified by this. Also, when you go on Twitter there are people treating Grok as a font of wisdom and truth, whereas the witnesses are making the point that they are not about finding truth. They are about finding plausible rather than factual things. What are the wider implications of this for our democracy? If you can ask ChatGPT how you can fix your car or how you should fix your broken toe, then you can presumably ask Grok or ChatGPT who you should vote for. What is the impact on the wider democratic sphere?</p>
        </speech>
        <speech by="#" eId="spk_109">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T12:15:00+00:00"/></from>
          <p eId="para_162">Presumably people are doing that. Grok is an interesting case because it is slightly less nuanced than a lot of the other systems mainly because of the character who is in charge of it. We saw a situation, which I am sure the committee is aware of, where Grok suddenly started recommending that people find out about the great replacement theory, just at the time when Trump was offering asylum to white South Africans. That was because it had been directly interfered with by its owner. That is a florid example and easy to dismiss. What I am really concerned about is the issue of education. As an educator, I can tell the committee that universities are on the front line of this issue. The constant narratives about how safe these systems are being made are really narratives about how to make this exact effect, just more subtly. What you are really introducing are powerful influencer systems, which seem to be a common concern of committee members. You are introducing a powerful but opaque influencing system into pretty much every question that everybody has about daily life.</p>
        </speech>
        <speech by="#PaulMurphy" eId="spk_110">
          <from>Deputy Paul Murphy<recordedTime time="2025-11-18T12:15:00+00:00"/></from>
          <p eId="para_163">I thank Dr. McQuillan. I will try to make it back for a second round, but I have to run to something.</p>
        </speech>
        <speech by="#JohnnyMythen" eId="spk_111">
          <from>Deputy Johnny Mythen<recordedTime time="2025-11-18T12:15:00+00:00"/></from>
          <p eId="para_164">When you are coming last you find that all the questions have been asked. It has been fascinating, and I thank the witnesses. It has been informative. I will start with the Electoral Commission. Catherine Connolly has already been spoken about. With a takedown note, there is how long the whole process takes, from the time it starts to when it finishes. That is fair enough. The opinion was that it was a well put together piece and it cost a lot of money. Is that traceable in terms of who created it, who spent the money on it to create it and is there a process for that?</p>
        </speech>
        <speech by="#" eId="spk_112">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T12:15:00+00:00"/></from>
          <p eId="para_165">The easy answer to this is "No", because we have no regulatory authority here, as I mentioned a couple of times. There was no criminal offence committed here.</p>
        </speech>
        <speech by="#JohnnyMythen" eId="spk_113">
          <from>Deputy Johnny Mythen<recordedTime time="2025-11-18T12:15:00+00:00"/></from>
          <p eId="para_166">It did have an influence. I was canvassing for Catherine Connolly and a number of people came out to tell me she was not running.</p>
        </speech>
        <speech by="#" eId="spk_114">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T12:15:00+00:00"/></from>
          <p eId="para_167">Yes, and the end of that video suggested that the election was over and one of the candidates would assume the Presidency the following day.</p>
        </speech>
        <speech by="#JohnnyMythen" eId="spk_115">
          <from>Deputy Johnny Mythen<recordedTime time="2025-11-18T12:15:00+00:00"/></from>
          <p eId="para_168">What authority does Coimisiún na Meán have in that area?</p>
        </speech>
        <speech by="#" eId="spk_116">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T12:15:00+00:00"/></from>
          <p eId="para_169">We do not have power to order the immediate takedown of content. The power we have is to make sure that the-----</p>
        </speech>
        <speech by="#JohnnyMythen" eId="spk_117">
          <from>Deputy Johnny Mythen<recordedTime time="2025-11-18T12:15:00+00:00"/></from>
          <p eId="para_170">The question I am asking is if we can find out how much it cost someone and who created it.</p>
        </speech>
        <speech by="#" eId="spk_118">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T12:15:00+00:00"/></from>
          <p eId="para_171">Our role is regulation of platforms and not the regulation of their users. We do not have an investigative role.</p>
        </speech>
        <speech by="#JohnnyMythen" eId="spk_119">
          <from>Deputy Johnny Mythen<recordedTime time="2025-11-18T12:15:00+00:00"/></from>
          <p eId="para_172">Does Mr. Godfrey think there should be regulation for that?</p>
        </speech>
        <speech by="#" eId="spk_120">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T12:15:00+00:00"/></from>
          <p eId="para_173">There are obviously freedom of expression issues. It is a matter for politicians what rules there should be about that.</p>
        </speech>
        <speech by="#JohnnyMythen" eId="spk_121">
          <from>Deputy Johnny Mythen<recordedTime time="2025-11-18T12:15:00+00:00"/></from>
          <p eId="para_174">If you have millionaires or billionaires who can put all this stuff together and influence the outcome of anything, does Mr. Godfrey not think there should be regulation on that, or a way to find out who spent the money and created the system?</p>
        </speech>
        <speech by="#" eId="spk_122">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T12:15:00+00:00"/></from>
          <p eId="para_175">The Deputy is getting a little beyond our role. There are issues about how money is spent to influence politics and what rules there are about spending money in election periods. Every democracy has those rules, and they are important. They may well be ones that ought to be updated for the current situation, but it is not really something that Coimisiún na Meán would be familiar with.</p>
        </speech>
        <speech by="#JohnnyMythen" eId="spk_123">
          <from>Deputy Johnny Mythen<recordedTime time="2025-11-18T12:20:00+00:00"/></from>
          <p eId="para_176">I thank Dr. McQuillan for his fair and robust critique. In Britain, there is a major pushback against AI, particularly with the deferring of critical thinking and people's functioning through cognitive expressions or that people cannot hold their focus for 30 seconds, which is having a devastating effect on young people. What is Dr. McQuillan's opinion on that? Does he think we should have far more regulation or robust legislation apart from regulation? </p>
        </speech>
        <speech by="#" eId="spk_124">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T12:20:00+00:00"/></from>
          <p eId="para_177">The ironic thing about the degradation of cognition is that it comes from one of the companies themselves. The primary piece of research was from a group of researchers that included Microsoft researchers. Microsoft is very involved because it is the partner of OpenAI, which is the company that produces ChatGPT. It did the initial research showing that how the overuse of these things in workplaces led to a reduction in people's capacity to think. We only have to ask anybody who works in a university or in a school right now about the kinds of effect that this is having. This is very much an after the horse has bolted situation. I am not a regulator or policymaker, but it is clear that, unfortunately under current conditions, society seems to have abandoned the idea that there should be a critical consideration of technologies before they are widely introduced. It is not too late in the sense that AI is not the end of it. As we all know, this thing is rapidly changing. A reconfiguration of the idea of regulation rather than trying to land it on everybody after it has already happened, and trying to get ahead of the game and say that technologies that influence society on a wide scale should be critically subject to social sanction and democratic critique before they are allowed to be released on society, would be a good start. </p>
        </speech>
        <speech by="#JohnnyMythen" eId="spk_125">
          <from>Deputy Johnny Mythen<recordedTime time="2025-11-18T12:20:00+00:00"/></from>
          <p eId="para_178">Young people are pushing back themselves. They are asking about how we allowed this to happen to them and how did we allow them to have an attention span of 30 seconds. Beyond that, they lose attention because of what they are used to looking at every day.</p>
          <p eId="para_179"> One of things on the area of AI that I have come across is the issue of intellectual property. For example, how should musicians, poets and writers be protected? </p>
        </speech>
        <speech by="#" eId="spk_126">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T12:20:00+00:00"/></from>
          <p eId="para_180">On young people, it is a sign for optimism in a way that they are increasingly questioning the prevalence of social media and AI. They are at least starting to put down their phones, get together with people and restart real life. </p>
          <p eId="para_181"> On the creativity side, it is an interesting question because that is something that has come to a lot of people's attention. My daughter is angry about the way AI is swallowing people's creative output. As referenced in my colleague's opening statement, if we are deriving our ideas about whatever the future should be and how we should create this future from things that have already happened in the past and we are massively closing off possibilities, be they in music, art or how society should be in general, then creativity in its broader sense is what is most under threat here.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_127">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:20:00+00:00"/></from>
          <p eId="para_182">It now falls to me. I am finding the conversation fascinating. One of the matters that has been mentioned by a number of the speakers has been the concept of trust, which is critical. I always see that technology is the means to the end rather than the end in itself. Sometimes, we lose track of that focus. I was conscious of how Professor MacCarthaigh spoke about AI-generated decisions and that it was critical that we have public accountability. I look to something like an MRI scan where AI is already transforming it, but it is still the human doctor at the end of the piece. We are talking about how the State will utilise AI. Where our recommendations are concerned, how can we guarantee public accountability within public administration?</p>
        </speech>
        <speech by="#" eId="spk_128">
          <from> Professor Muiris MacCarthaigh<recordedTime time="2025-11-18T12:20:00+00:00"/></from>
          <p eId="para_183">The comments by Senator Ryan were perceptive. We are discussing a lot here today between the democratic dimension, the nature of political contestation, the actual regulation of the electoral process and then the other side of it-----</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_129">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:20:00+00:00"/></from>
          <p eId="para_184">I will be coming to that in a minute. I am asking specifically on public administration. </p>
        </speech>
        <speech by="#" eId="spk_130">
          <from> Professor Muiris MacCarthaigh<recordedTime time="2025-11-18T12:25:00+00:00"/></from>
          <p eId="para_185">Absolutely, yes. It is happening very quickly. In fact, some of our students are doing PhDs on the different dispositions of public service to accept or, in some cases, have the confidence to critically use AI and say, "Right, that is what it is saying but I do not believe it and I am going to look myself." The essential issue here is, as Dr. Padmanabhan has mentioned, that the fundamental nature of public administration is accountability for process and that is really being challenged by AI.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_131">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:25:00+00:00"/></from>
          <p eId="para_186">How can we address it?</p>
        </speech>
        <speech by="#" eId="spk_132">
          <from> Professor Muiris MacCarthaigh<recordedTime time="2025-11-18T12:25:00+00:00"/></from>
          <p eId="para_187">I guess we are into issues around skills and capacities of public servants. This is why I referred earlier to the nature of being a public servant because if this keeps going the way it is going, that is going to fundamentally change.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_133">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:25:00+00:00"/></from>
          <p eId="para_188">I favour compulsory AI skills training for public servants, particularly senior public servants. Would Professor MacCarthaigh support that idea?</p>
        </speech>
        <speech by="#" eId="spk_134">
          <from> Professor Muiris MacCarthaigh<recordedTime time="2025-11-18T12:25:00+00:00"/></from>
          <p eId="para_189">There is something to be said about improving competence and capacity if this is unavoidably going to be part of the story of being a public service. We often talk about generalists versus specialists, but certainly having access to people who understand how decisions are being arrived at in the black box is really important insofar as possible. There is an onus then on the technology and services that are being purchased by the State to perform. There is absolutely no doubt about the efficiencies. I see the British Government has introduced new systems, as mentioned earlier, to bring together historical data very quickly to help decision-making, not to make the decision but just get it there in front of people, rather than them having boxes and boxes of notes. There is, therefore, a bit from regulating what is coming into government but also the competence and capacity skills within the public service as well.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_135">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:25:00+00:00"/></from>
          <p eId="para_190">We briefly discussed the security of our elections, which is critical to our democracy. A number of colleagues referred to the presidential election. I saw the Catherine Connolly deepfake and I did not believe in it but there were people who did, which surprised me. Hopefully, we will not have a general election until 2029. By that stage, AI technology and its ability - we have seen how deepfakes are developing - will be far more advanced. The presidential election was one election. Obviously, a general election means over 40 different elections will happen and deepfakes will be far more advanced. We have not really touched on the issue of chatbots but I want to talk about how malign actors, including state actors, are looking to influence our democracy. I am thinking, in particular, of Russia. We have seen in elections in Romania and Moldova that there has been an external influence. How prepared are we for that for the next general election in 2029? What is An Coimisiún Toghcháin doing to prepare for that? What more does the State need to do? The representatives from An Coimisiún na Meán may also wish to comment on that.</p>
        </speech>
        <speech by="#" eId="spk_136">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T12:25:00+00:00"/></from>
          <p eId="para_191">The solution from our perspective is all about education, information, public engagement and digital literacy. These four elements will be the centrepiece of our education and public engagement strategy, which we hope to publish in the next years. We will devote a huge amount of resources between now and the next general election to doing all of these things, answering all of these questions and informing people. Deputy Mythen mentioned people not knowing who to vote for. One third of the people who did not vote in the last election said it was because they did not know who to vote for, they did not think politics had anything to do with them or that their single vote did not count. This is a very important audience for us. It is not just about voters; it is about how to deal with non-voters to get them engaged in public service.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_137">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:25:00+00:00"/></from>
          <p eId="para_192">Is there evidence of outside interference or, to be blunt, Russian chatbots or other actors outside the State seeking to undermine our democracy?</p>
        </speech>
        <speech by="#" eId="spk_138">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T12:25:00+00:00"/></from>
          <p eId="para_193">We have no evidence of that. The deepfake in the presidential election was really the first more sophisticated one that we had a look at. We had seen a couple of homegrown attempts at this, which people were-----</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_139">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:25:00+00:00"/></from>
          <p eId="para_194">Where does An Coimisiún Toghcháin suspect it came from?</p>
        </speech>
        <speech by="#" eId="spk_140">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T12:25:00+00:00"/></from>
          <p eId="para_195">I have no idea, to be honest. I have seen schools of thought say it must be international and then, because of the internal reactions, people are saying it must be homegrown. Given that it is easy to create deepfake videos, it would be too hard to establish that without a proper investigation.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_141">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:30:00+00:00"/></from>
          <p eId="para_196">I might ask Coimisiún na Meán to comment on that also, particularly in light of the experience of other member states.</p>
        </speech>
        <speech by="#" eId="spk_142">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T12:30:00+00:00"/></from>
          <p eId="para_197">I absolutely agree with An Coimisiún Toghcháin on the importance of education. You can regulate all you like, but you also have to build societal resilience in order that people are sceptical and have the necessary critical skills. It is interesting that the Cathaoirleach mentioned Russia. Across the EU, the member state which has the best reputation for media literacy is Finland. That is because for years the Finns have been worried about cross-border interference. That is built into the school curriculum from primary school upwards. It is not a quick process to build societal resilience.</p>
          <p eId="para_198"> An Coimisiún Toghcháin has its education programmes. We have ours. Before the European elections, we ran the "Stop/Think/Check" campaign to help people and make them alert to the possibilities in this regard. However, that is really a whole-of-society issue.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_143">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:30:00+00:00"/></from>
          <p eId="para_199">I commend the regulators on their public information campaigns. However, what should we be building into our formal education system to address some of this?</p>
        </speech>
        <speech by="#" eId="spk_144">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T12:30:00+00:00"/></from>
          <p eId="para_200">Critical thinking skills. There are great things that have been done in terms of asking people to create misleading content in the classroom, and they become much better at then recognising other people. That needs to be built into the civic, social and political education, CSPE, curriculum.</p>
        </speech>
        <speech by="#" eId="spk_145">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T12:30:00+00:00"/></from>
          <p eId="para_201">Last year and this year, we ran campaigns in respect of the elections. The tag line was very simple. It was to the effect that if there is one day of the year when you question everything that you read, see and hear, it is April Fool's Day. The message to people was that during an election campaign, they should treat every day like April Fool's Day and ask where information is coming from, who benefits from it and where is the best place to go to check it. That went viral because it captured the imagination of young people in particular. It is those kinds of campaigns that we need to start investing in. We need to speak in a language that people understand, because, as the Cathaoirleach mentioned, this is moving very quickly. In the context of the 2020 general election, TikTok did not exist. By 2024, it was the main communications channel for us in respect of young people. Who knows what will be in 2029?</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_146">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:30:00+00:00"/></from>
          <p eId="para_202">I am conscious of the time. We will allow one more round and then come back to people to allow them to have a final word. I will allow four minutes each for the second round. I call Senator Dee Ryan.</p>
        </speech>
        <speech by="#DeeRyan" eId="spk_147">
          <from>Senator Dee Ryan<recordedTime time="2025-11-18T12:30:00+00:00"/></from>
          <p eId="para_203">I am going to focus on the tech side of the contributions. I thank the witnesses. They gave us an awful lot to think about. I was struck by the observations they made about considering the appropriateness of deploying AI or any other advanced technology in respect of sensitive public data or the delivery of public services. Are there any examples in other states of situations where AI has been used well to enhance the delivery of public services?</p>
        </speech>
        <speech by="#" eId="spk_148">
          <from> Dr. Deepak Padmanabhan<recordedTime time="2025-11-18T12:30:00+00:00"/></from>
          <p eId="para_204">While not exactly an example of a state using it in the context of a public service, the overall architecture of an information service - not really a public service - working well can be found in certain alternatives such as, for example, Wikipedia. Wikipedia is a social media in its own right. There are a lot of people working on it, commenting on each other's work and editing stuff, but it largely becomes a more authoritative place the more people are there. On the other hand, the more people get involved with corporate social media, the more misinformation ridden it becomes. That could be due to various reasons. One of the possible reasons could be that its ownership model is not profit oriented. We talk about disinformation quite a bit. Disinformation also happens because there is somebody profiting from it, not just by means of electoral outcomes but by means of real money. In other words, somebody is making money out of the engagement that it generates, etc. If we have systems that have their motives right and maybe people working in the interests of societal good rather than for monetary benefit, maybe we will get to nice systems.</p>
        </speech>
        <speech by="#DeeRyan" eId="spk_149">
          <from>Senator Dee Ryan<recordedTime time="2025-11-18T12:35:00+00:00"/></from>
          <p eId="para_205">I thank Dr. Padmanabhan for those observations. I was curious whether he had any particular example in mind when he put his piece together. We are going to have a session looking at other states and where this is used well. I am more interested in exploring whether there are opportunities for us to take information we already hold in different sections of the State and to use technology to better serve people, for example, through automatically flagging when people become entitled to something and pushing relevant applications to them. We will get onto that.</p>
          <p eId="para_206"> Another thought struck me when I was listening to the contributions of the three witnesses. I share their concern around LLMs. They have made the point very well that the information that comes from LLMs is only as good, strong and reliable as the sources it comes from. Are there discussions in any areas of academia with regard to developing discipline-specific or sector-specific LLMs that would rely on highly credible sources of information? Are there any discussions in academia around that at present?</p>
        </speech>
        <speech by="#" eId="spk_150">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T12:35:00+00:00"/></from>
          <p eId="para_207">The discussion around such an industry rubric would come under small language models. There is a kind of narrative around that. The problem there is that it is not only about the data, but also about the mode of processing. As I alluded to at the beginning, the mode of processing does not have any factuality or causality in it. What you are really looking for in these things is not just a carefully curated dataset but a situation where essentially unreliable information is functional, which applies to a fairly narrow range of things. You are really looking for a situation where only the form of the output is important. It could be imagined that, in some very limited situations of language learning, a language model like that might be useful because it is more about imitation. However, for things that actually require novel output that can be relied on in the real world, there are no uses for it.</p>
        </speech>
        <speech by="#DeeRyan" eId="spk_151">
          <from>Senator Dee Ryan<recordedTime time="2025-11-18T12:35:00+00:00"/></from>
          <p eId="para_208">Dr. McQuillan is sceptical of the assumptions that are made in the interpretation of the data, no matter how reliable the data is.</p>
        </speech>
        <speech by="#" eId="spk_152">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T12:35:00+00:00"/></from>
          <p eId="para_209">It is not just about the data. It is about what happens to it when it gets shoved into these things. What happens is that it gets made into something you cannot trust.</p>
        </speech>
        <speech by="#DeeRyan" eId="spk_153">
          <from>Senator Dee Ryan<recordedTime time="2025-11-18T12:35:00+00:00"/></from>
          <p eId="para_210">I thank Dr. McQuillan for raising all of those concerns.</p>
        </speech>
        <speech by="#JamesGeogheganFG" eId="spk_154">
          <from>Deputy James Geoghegan<recordedTime time="2025-11-18T12:35:00+00:00"/></from>
          <p eId="para_211">This has been a really interesting discussion for us. Like Senator Ryan, I will thank the witnesses for having shown up to this committee meeting and having given very important contributions. I would not like them to think I am not interested in what they have to say.</p>
          <p eId="para_212"> Dr. McQuillan said something interesting. I do not want to misquote him but it was about AI sovereignty. If I understood him correctly, he said that the debate is not really about that and that it is being framed wrongly. I just wanted to tease that out a little bit. In my own mind, it is all about AI sovereignty because, if state actors or private actors are going to rely on one of these 11 LLM companies, which are all fighting with one another and which are, as Mr. Godfrey said, in a race with one another for profit, while various aspects of the private sector, the public sector and the State are feeding off these LLMs in their own specialist areas, it is not essential that we have as much control as possible over what these LLMs are doing, what they are producing and how the benefits are harnessed?</p>
        </speech>
        <speech by="#" eId="spk_155">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T12:35:00+00:00"/></from>
          <p eId="para_213">I completely accept the premise in the sense that there are real risks to sovereignty here. I understand why that is a primary concern. I will break it down in a couple of ways. To follow on from what I was saying, there is a kind of algorithmic sovereignty problem based on the way the algorithms actually work. You cannot really control what they are doing, if that is what sovereignty means, or rely on the outputs. Stepping back a little bit to the more political economy side of it, there are a couple of problems. One is the narrative around sovereignty and the way it has evolved. All of the big companies are, in a way, offering sovereignty as a service at the moment. They have cottoned on to this, at least since 2022 or 2023. The big companies like Google, Microsoft, OpenAI, Amazon and some of the other large language model companies are saying that they will provide sovereignty. They say they will provide governments with control over data, privacy, compliance and all of these things while eliding the fundamental relationship, which is that these are services they are then in control of providing to you rather than something you actually control.</p>
        </speech>
        <speech by="#JamesGeogheganFG" eId="spk_156">
          <from>Deputy James Geoghegan<recordedTime time="2025-11-18T12:40:00+00:00"/></from>
          <p eId="para_214">As to whatever they say, fair enough, it may be their show, but surely our job as legislators, as in states all around the world, is to act in these matters. This is not the first time we have seen the private market create something from which the State then benefits but that we are not able to regulate or control. This is a fundamental shift, which, depending on one's perspective, could be as significant as the industrial revolution or that is, at least, the language being used. Is Dr. McQuillan of the view that the State is currently incapable of providing some level of control? Is that his concern?</p>
        </speech>
        <speech by="#" eId="spk_157">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T12:40:00+00:00"/></from>
          <p eId="para_215">I will make three points. The narrative of an industrial revolution is very much a narrative of the industry itself. Second, it is not regulatable for reasons that have already been covered. Third, the cake is not worth the candle in that what is coming out of this at the end is not the kind of thing the State or society will really benefit from because the benefits of these things are not what they are cracked up to be. I would really urge the diversion of some of the attention, money and even enthusiasm that is present around AI into things that have more concrete and demonstrable benefits.</p>
        </speech>
        <speech by="#JamesGeogheganFG" eId="spk_158">
          <from>Deputy James Geoghegan<recordedTime time="2025-11-18T12:40:00+00:00"/></from>
          <p eId="para_216">However, the money is coming from these private actors. Yes, the State is investing here and there in it but, in relative terms, the bazillions are coming from private actors who are saying this is going somewhere and we will benefit from it.</p>
        </speech>
        <speech by="#" eId="spk_159">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T12:40:00+00:00"/></from>
          <p eId="para_217">There is a lot of private money involved. I read daily AI news bulletins about the various deals that have been done. I am sure the Deputy is aware of them. This is not just about the bubble but also simply about the dealmaking that happens in the AI industry. There is not really a figure under some number of billions in any of these deals. We must consider several factors about where that money is coming from. Certainly, in the UK, which I know more about than I do about Ireland, most of those companies are not being taxed at all. The money being generated is, in essence, free money that then recycles through the venture capital system. The reason venture capitalism is so important comes from the kinds of measures that were taken to allegedly deal with the financial crisis of 2008. That is what freed up a lot of the money going into venture capital for all these speculative investments. There is a lot of unpicking to do but I really do not think the fact these companies have the money and power at the moment should be a starting point for how any state or sovereign entity should deal with the issue.</p>
        </speech>
        <speech by="#JamesGeogheganFG" eId="spk_160">
          <from>Deputy James Geoghegan<recordedTime time="2025-11-18T12:40:00+00:00"/></from>
          <p eId="para_218">I thank Dr. McQuillan. I have another question for the witnesses from Queen's University that I did not get to ask earlier.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_161">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:40:00+00:00"/></from>
          <p eId="para_219">The Deputy will have to be very brief.</p>
        </speech>
        <speech by="#JamesGeogheganFG" eId="spk_162">
          <from>Deputy James Geoghegan<recordedTime time="2025-11-18T12:40:00+00:00"/></from>
          <p eId="para_220">It concerns the all-island dimension, which is why I am asking it of the Queen's University representatives. I am interested in whether there is an all-island dimension. Obviously, the United Kingdom is not part of the European Union. We have the AI Act and the UK is doing what it is doing. Is there a risk of regulatory abritrage, divergence or convergence in terms of how AI is operating south versus north of the Border?</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_163">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:40:00+00:00"/></from>
          <p eId="para_221">I will see whether the witnesses can answer that in 30 seconds.</p>
        </speech>
        <speech by="#" eId="spk_164">
          <from> Professor Muiris MacCarthaigh<recordedTime time="2025-11-18T12:40:00+00:00"/></from>
          <p eId="para_222">There has been no AI strategy from the Executive north of the Border but there is one here and in Britain. There absolutely are digital borders. That is an issue but I suppose we will have to come back to it. I am sorry if that is not very helpful.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_165">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:40:00+00:00"/></from>
          <p eId="para_223">We might specifically explore that in a separate session.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_166">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-11-18T12:40:00+00:00"/></from>
          <p eId="para_224">I will also direct my questions to the academics in the room. They stated that GDPR and the AI Act are preliminary steps to ensuring AI serves the public good and that they should be expanded rather than narrowed. Have all three of the academic witnesses read the draft of the digital omnibus and are they concerned about the row-back on regulation at EU level?</p>
        </speech>
        <speech by="#" eId="spk_167">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T12:40:00+00:00"/></from>
          <p eId="para_225">I will have a crack at that question. I have read some of the omnibus and it probably goes without saying that I am deeply concerned, if only because the AI Act itself was a set of compromises that really started from the point of view of product safety rather than human or civil rights or any other broader set of values. It was already a lesser way of dealing with AI and it is turning out to be a bit of a paper tiger in practice. It is a very pivotal moment for any government to think about how to deal with AI because the cover that might have been provided by something like the AI Act is clearly not going to hold.</p>
        </speech>
        <speech by="#" eId="spk_168">
          <from> Professor Muiris MacCarthaigh<recordedTime time="2025-11-18T12:40:00+00:00"/></from>
          <p eId="para_226">I have read the omnibus but I have been more about observing what is something of a global race to try, somehow, to keep abreast of AI developments between the EU Act, the legislation in the United States and China developing its regulatory frameworks.</p>
          <p eId="para_227">We are in the middle of this phenomenon where the technological advances are happening quicker than the governance and while the State can do an awful lot, it can only do it in collaboration with other states. It is quite a task to keep pace with the levels of technological change, as we have heard.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_169">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-11-18T12:45:00+00:00"/></from>
          <p eId="para_228">I am going to use the remainder of my time to ask about something I have been describing as access to justice. However, there is another term I have been introduced to recently that is more helpful, namely, accountability sync. This is the idea that bad things that happen to people can be attributed to wider systems rather than a specifically blameable person or initiative. A lot of us will be familiar with the phenomenon of "Computer says 'No'". How do we avoid this because with large language models, there is a real danger in this area? Certainly in terms of decision-making within the public sector, this is a huge issue. Do the witnesses have any suggestions for avoiding this?</p>
        </speech>
        <speech by="#" eId="spk_170">
          <from> Dr. Deepak Padmanabhan<recordedTime time="2025-11-18T12:45:00+00:00"/></from>
          <p eId="para_229">I did not quite understand the question. The Deputy spoke about accountability. Could she say the first part again please?</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_171">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-11-18T12:45:00+00:00"/></from>
          <p eId="para_230">Accountability sync, which is the idea that when we have such a distributed model, there is no single person or point where blame or accountability can be attributed.</p>
        </speech>
        <speech by="#" eId="spk_172">
          <from> Dr. Deepak Padmanabhan<recordedTime time="2025-11-18T12:45:00+00:00"/></from>
          <p eId="para_231">That is partly because of the lack of transparency of these models. We are looking at taking a lot of data and these data are created by specific people all around the world. A caseworker in a public service exercises agency whereas here, the decision comes out of a number of data points that are distilled through a number of algorithmic pipelines, so there is the notion of distributed agency. When the agency of the decision cannot be attributed to one particular actor but across a lot of different actors, it becomes hard to maintain accountability. We cannot hold somebody to account.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_173">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-11-18T12:45:00+00:00"/></from>
          <p eId="para_232">Are there ways to avoid that? Introducing AI into public sector practices is a real nightmare when we accept that as just a part of the system. What can we do to avoid that?</p>
        </speech>
        <speech by="#" eId="spk_174">
          <from> Dr. Deepak Padmanabhan<recordedTime time="2025-11-18T12:45:00+00:00"/></from>
          <p eId="para_233">When we talk about AI, we generally talk about it as a monolithic database but there are different flavours of AI. One of the earlier flavours of AI, which is now called good, old-fashioned AI and is no longer in the picture, is something called symbolic AI, which essentially is about authoring rules. These systems operate by way of rules so we can trace the provenance of the decision back to a particular aspect. It is a little bit like industrial automation. If a printing press is not working, we can drill down to determine which particular part of the machine is causing it to break. In that sense, we can work backwards and find out which rule caused it to fail. There are those kinds of AI systems that have an inherent transparency to them, in contrast to the systems that we have now like large language models. Maybe LLMs could imbibe some sort of flavour of those and there are explorations in that direction. Dr. McQuillan talked earlier about small LLMs and there are ways of infusing human knowledge into LLMs in a very transparent way. There are explorations but it is still early days.</p>
        </speech>
        <speech by="#SineadGibney" eId="spk_175">
          <from>Deputy Sinéad Gibney<recordedTime time="2025-11-18T12:45:00+00:00"/></from>
          <p eId="para_234">Thanks. I know I am over time but does anyone else want to add to that?</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_176">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:45:00+00:00"/></from>
          <p eId="para_235">I will let Dr. McQuillan in for 20 seconds.</p>
        </speech>
        <speech by="#" eId="spk_177">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T12:45:00+00:00"/></from>
          <p eId="para_236">I just wanted to mention the concept, because it comes up so much in these kinds of discussion, of the human in the loop, whether the loop is symbolic AI or the kind of AI that we have got, which is the fundamentally opaque type. Apart from the fundamental opacity being an abandonment of due process, I just want to point out that the human in the loop in itself does not solve these problems because having a human in the loop is not due process <i>per se</i>. Also, the human in the loop in an algorithmic environment is subject to all of those same kinds of automation bias and choice architecture that we already find in social media. We certainly, in any of these conversations, need to go far beyond having a human in the loop.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_178">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:45:00+00:00"/></from>
          <p eId="para_237">It is a such sign of how far we have moved already when Dr. Padmanabhan refers to "good, old-fashioned AI". </p>
        </speech>
        <speech by="#PaulMurphy" eId="spk_179">
          <from>Deputy Paul Murphy<recordedTime time="2025-11-18T12:45:00+00:00"/></from>
          <p eId="para_238">Related to that and to the Electoral Commission, the witnesses mentioned earlier the potential of using AI for a first draft of boundary commission reviews. While I accept there is a lot of data and it is a question of numbers but also geography, it is concerning to me that we would consider that.</p>
          <p eId="para_239">It is linked to what Dr. McQuillan is saying. I accept that it is only the first step and that there will be a human who looks at it, but, obviously, the first proposal has a privileged status. We all know that in the context of our work. If you go to a committee and bring the proposal, people will react to that proposal. That is the starting point. They can amend it this way or that way, but it is the starting point. Effectively, Mr. O'Leary is saying that he is considering and would be open to the idea that we would give first-mover advantage to AI in what is a very fundamental part of our entire democratic system in the context of the nature of our constituencies and how TDs are elected. I invite him to expand a little on that. Does he share those concerns.</p>
        </speech>
        <speech by="#" eId="spk_180">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T12:50:00+00:00"/></from>
          <p eId="para_240">There is a question of time here. The results of the census will be out in May 2028, and the next scheduled general election is November 2029. It normally takes a year to carry out the constituency review. The two most recent reviews have been done by crunching Excel spreadsheets, maps and so on. We need to look at technology. It may not necessarily be AI. There are algorithms and so on that might be able to help us speed up this process. After we report, the Oireachtas has to legislate to introduce them. The Venice Commission says there should be no changes to constituencies for at least a year in advance of a general election. There is a particular challenge here that we have to deal with. We have not settled on what it might look like. We also have to do the local electoral area boundaries, the Dáil constituencies and European Parliament constituencies within that very compressed period. If I can offer the Deputy some reassurance, it is to say that I do not think there was a single constituency of the 43 where the first option lasted and was sustained over the seven members of the commission looking at it. There are so many tweaks, etc. There is no benefit to first-mover advantage in the context of that simple crunching of the numbers the first time out.</p>
        </speech>
        <speech by="#PaulMurphy" eId="spk_181">
          <from>Deputy Paul Murphy<recordedTime time="2025-11-18T12:50:00+00:00"/></from>
          <p eId="para_241">I am sceptical about that. There is always a first-mover advantage. Mr. O'Leary used the word "tweaking".</p>
        </speech>
        <speech by="#" eId="spk_182">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T12:50:00+00:00"/></from>
          <p eId="para_242">I was in the room. It was the first time we did it because the Electoral Commission is new. We look at issues, including boundaries. Things like county boundaries were difficult for us. The people of Urlingford and Freshford still keep me awake at night.</p>
        </speech>
        <speech by="#PaulMurphy" eId="spk_183">
          <from>Deputy Paul Murphy<recordedTime time="2025-11-18T12:50:00+00:00"/></from>
          <p eId="para_243">I hope the people of Fettercairn do too.</p>
          <p eId="para_244"> Dr. McQuillan stated that even the engineers who build AI cannot explain what is going on inside. As a result, reliable regulation is a non-starter. I am coming from a very similar place in terms of the conclusions I have reached so far on the basis of our discussions. If it cannot be regulated, then should it be banned? How would we actually do that and what would it look like?</p>
        </speech>
        <speech by="#" eId="spk_184">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T12:50:00+00:00"/></from>
          <p eId="para_245">I would not presume to step on the toes of people in the room when it comes to legislating for things. My emphasis really would be on taking AI as a diagnostic in the context of saying where people are - and, following on from what our colleague from the Electoral Commission said - talking about situations where they say that AI does seem to be an option because they are under incredible pressure and do not have enough resources and so on. That is such a universal narrative, wherever we look. It certainly is in the area of higher education. People say there is this AI thing that they can turn to. I would say it is always a point at which people should be asking, and this does rise up to the legislative level, what else they could do. If there really is not enough time to do that, why is there not enough time? If there really are not enough teachers, why are there not enough teachers? Is this really a matter of overall social resources? We were just talking about the amount of money that is flowing around the tech sector. Is it really that there are not enough resources to provide enough teachers or whatever? That provides the contextual and relational way of doing things, which, historically and currently, turns out to be far more reliable than turning to these magic machines.</p>
        </speech>
        <speech by="#PaulMurphy" eId="spk_185">
          <from>Deputy Paul Murphy<recordedTime time="2025-11-18T12:50:00+00:00"/></from>
          <p eId="para_246">Thanks a lot.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_186">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:50:00+00:00"/></from>
          <p eId="para_247">The school of physics in Trinity made an algorithmic-based submission to the Electoral Commission. I thought it was horrific, and I am glad it was not followed up. However, an algorithm was used for it.</p>
        </speech>
        <speech by="#" eId="spk_187">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T12:50:00+00:00"/></from>
          <p eId="para_248">There might be some good ideas, but not always. This is why you can never replace people or the human eye, but perhaps it might be an idea when it comes to generating first drafts.</p>
        </speech>
        <speech by="#JohnnyMythen" eId="spk_188">
          <from>Deputy Johnny Mythen<recordedTime time="2025-11-18T12:55:00+00:00"/></from>
          <p eId="para_249">On the phrase used there, as experts, do the witnesses think there is a possibility of AI ever becoming its own agency?</p>
        </speech>
        <speech by="#" eId="spk_189">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T12:55:00+00:00"/></from>
          <p eId="para_250">We need to be alive to the possibility that it could happen. There are challenges and benefits to all of these things. The decision would have to be made in due course to ensure the integrity not just of elections but wider democracy and public services.</p>
        </speech>
        <speech by="#" eId="spk_190">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T12:55:00+00:00"/></from>
          <p eId="para_251">Again I am in a far easier position since I do not have to make the rules or the policies. The really interesting thing about AI is exactly the discussion in the room. It brings almost everything together under one set of questions because AI is trying to condense all of the really important questions of our time and is trying to have an effect on all of them. Perhaps that challenges the way decisions are currently made in the forms of silos we currently have. When we are thinking about impacts of AI, we need to be thinking about everything at the same time.</p>
        </speech>
        <speech by="#JohnnyMythen" eId="spk_191">
          <from>Deputy Johnny Mythen<recordedTime time="2025-11-18T12:55:00+00:00"/></from>
          <p eId="para_252">There was reference made to deals. A deal was recently done in Silicon Valley which was done in respect of a quadrillion. That is the type of money we are talking about. On decision-making and public services, the witnesses spoke about the exclusion of marginalised groups. Maybe they could elaborate on that. We had a couple in here, particularly in respect of people with disabilities. The people who are forming these codes and programmes have not got a clue about people with disabilities but they are actually forming the codes that make the decisions.</p>
        </speech>
        <speech by="#" eId="spk_192">
          <from> Professor Muiris MacCarthaigh<recordedTime time="2025-11-18T12:55:00+00:00"/></from>
          <p eId="para_253">On the agency issue, we would say to students that AI operates in the medium of the Internet and the Internet is full of rubbish. It is in a stage now where it is producing information that is itself then forming part of that slop, as it is being called. This issue of marginalisation and discrimination is one we have worked quite a lot on. Dr. Padmanabhan has worked on that.</p>
        </speech>
        <speech by="#" eId="spk_193">
          <from> Dr. Deepak Padmanabhan<recordedTime time="2025-11-18T12:55:00+00:00"/></from>
          <p eId="para_254">On the agency thing, it is a very interesting point. When we talk about human agency, it is about looking backwards and seeing how we reached the underpinning reasons behind the phenomenon we are analysing, and then maybe looking forwards at where we should reach and so on. There is a historical nature to human agency that is not something any machine can replace. Machines at the end of the day are programmed to work in a particular way. They might be very sophisticated but they do what they are instructed to do. As long as they are dependent on the data, and the data is generated by humans who live in a society where there are stereotypes and so on, that necessarily transfers over to AI to cause discriminatory things. By default, AI will be discriminatory. We need to actively get it to be non-discriminatory, as it were. It is in its DNA, so to speak, that it would be discriminatory.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_194">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:55:00+00:00"/></from>
          <p eId="para_255">The role of our committee is that we advise the Government and look at different policy areas. Given that we touched on public administration, one of the areas we touched on in this committee before which has been explored is the use of agentic AI, particularly in areas like procurement and so on. One of our biggest complaints is about how long everything takes. There is potential but obviously there are dangers involved as well. If Professor MacCarthaigh was specifically looking at the State using agentic AI in procurement or other areas, would he recommend doing it and what safeguards might he consider putting in place?</p>
        </speech>
        <speech by="#" eId="spk_195">
          <from> Professor Muiris MacCarthaigh<recordedTime time="2025-11-18T12:55:00+00:00"/></from>
          <p eId="para_256">The State is an enormous procurer all the time. It is very attractive to speed up efficiencies that we would use AI to do first cuts, to narrow or to try to synthesize information in a way that takes a long time for public servants to do by hand, as it were. I do not have a specific model. It is a very specific issue. I do not think I could recommend something that quickly. I would have to come back to the Cathaoirleach on it, I am sorry. I do not know if my colleagues might have a suggestion.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_196">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T12:55:00+00:00"/></from>
          <p eId="para_257">We have touched on the issue of agentic AI and the fascinating topic of procurement. As I am getting looks of horror, I will move on to wrapping up.</p>
          <p eId="para_258">We are looking at truth and democracy; we really value the democracy we have; and we know that AI is with us. In terms of our recommendations and the approach to the State, will each witness suggest what we should be looking at or if there is a specific recommendation? I will go to Mr. O'Leary and Mr. Callan first. </p>
        </speech>
        <speech by="#" eId="spk_197">
          <from> Mr. Art O'Leary<recordedTime time="2025-11-18T13:00:00+00:00"/></from>
          <p eId="para_259">As I mentioned earlier, I think the solution to all these challenges is education, public engagement and digital literacy. This is where the focus of all of our energy will be in the next couple of years. AI is here. I think we have to manage it and mitigate whatever risks we have. I did not get to mention it but one of the big challenges we have is the issue of labelling AI. There is so much material being generated here. There is a danger if we say we are going to label anything that is AI, if some material emerges that is not labelled then people will automatically think it is true. We have to be very careful about offering what are, on the face of it, quite simple solutions where it is much more complex than that. </p>
        </speech>
        <speech by="#" eId="spk_198">
          <from> Dr. Dan McQuillan<recordedTime time="2025-11-18T13:00:00+00:00"/></from>
          <p eId="para_260">I would like to question the concept that education is the answer, not to directly criticise my colleagues but just because it has come up several times. It is incumbent on me as a member of the higher education sector to say that education is exactly what is most being undermined right now. Education is the front line of the social impacts of AI. If we are thinking about education, we need to think about what is happening to it right now and not place hopes in what it might do in the future because it is education that is really struggling under the impact of these technologies. </p>
          <p eId="para_261"> What I would promote, in line with my earlier suggestions, is a great deal of caution and the erection of as many safeguards at as many levels as possible. I do not actually accept the premise that AI is here to stay. I would say look at some of the pronouncements as in today's news by Sundar Pichai about the likelihood of a massive correction on AI. On thinking "But never mind, it will still have a future afterwards", there are indicators that maybe it does not have a future after this and definitely not in this form. It would be very wise for people who have the responsibilities of the State to bear that in mind. There is a longer game here that is about building on the strengths of something like Ireland already has in my understanding, which is a still-existing system of social relationships that hold up society in the first place. AI is fundamentally toxic to that. It is the asbestos of social relationships. </p>
        </speech>
        <speech by="#" eId="spk_199">
          <from> Professor Muiris MacCarthaigh<recordedTime time="2025-11-18T13:00:00+00:00"/></from>
          <p eId="para_262">On what the committee is doing, the co-ordination between the state bodies and interests responsible for regulating the different ways in which AI is affecting different parts of democracy and government is important. Even the creation of this committee of itself, to have a forum to bring people together and make sure there are no gaps in the broad regulatory framework, is a good idea. It is about trying to keep as best we can some kind of handle on things. </p>
        </speech>
        <speech by="#" eId="spk_200">
          <from> Dr. Deepak Padmanabhan<recordedTime time="2025-11-18T13:00:00+00:00"/></from>
          <p eId="para_263">I will say something about the general picture of AI. When we talk about AI, we think of it as a huge product which can only be built by the private corporations. AI tends to bring up questions of privatisation because it is always a private company which would sell us the service. We ought to mind that the technology is socially constructed in the sense that a technology that is built elsewhere may not be applicable as much to the concrete realities of the place we are in. That also speaks to the discussion on alternatives. Maybe there is a place to start small. Maybe there is a place to have a small technology office within the Government to build bespoke AI technology for a particular public service. Maybe we will see the challenges we are facing there and maybe that will bring up the contrast between the AI that is out in the market and the AI built within the Government and maybe that will lead us to somewhere we might not be able to foresee at this point.</p>
        </speech>
        <speech by="#" eId="spk_201">
          <from> Mr. Jeremy Godfrey<recordedTime time="2025-11-18T13:00:00+00:00"/></from>
          <p eId="para_264">It is useful to centre this in wider concerns about the health of the information space. The information space is critical to democracy. Even before we were concerned about deepfakes and AI chatbots, we were worried about how social media recommender systems were poisoning the information space. That to me is crucial. AI just amplifies those risks in the information space.</p>
          <p eId="para_265"> On concrete suggestions to the committee, the plurality of obligations that might be placed on providers of AI chatbots and social media feeds to make sure that does not poison the information space, or at least gets rid of some of the poison in the information space, is really important. At the moment, we are in a situation where people do not know what is true. In fact, the whole concept of truth is being undermined. If ours is a society that can at least agree that there is such a thing as truth, even if we disagree about what the truth is, that is really important. That is what is what is fundamental here.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_202">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T13:05:00+00:00"/></from>
          <p eId="para_266">Is there anything Ms Pollock would like to add?</p>
        </speech>
        <speech by="#" eId="spk_203">
          <from> Ms Anne-Marie Pollock<recordedTime time="2025-11-18T13:05:00+00:00"/></from>
          <p eId="para_267">I think it has been covered. Mr. O'Leary's points on education are key, as are those of my colleagues on my left. Media literacy and sharing best practice across member states is something that has huge benefits. That piece of truth keeps coming up. High-quality journalism and funding for it are also key.</p>
        </speech>
        <speech by="#MalcolmByrne" eId="spk_204">
          <from> An Cathaoirleach<recordedTime time="2025-11-18T13:05:00+00:00"/></from>
          <p eId="para_268">I thank everyone very much. As people will remember, in terms of truth and democracy and advancing technology, we carried out an experiment in this country with electronic voting machines. Even in spite of the fact that the technology has advanced enormously, it would be a very brave politician who would suggest bringing them back. Technology should always be seen as the means rather than the end.</p>
          <p eId="para_269"> Today's discussion has been insightful and really interesting. I say that on my behalf and on that of my colleagues. I thank the witnesses for their input and their continued work. Part of our job is to develop this debate. None of us is a total expert in this space. We are all learning.</p>
        </speech>
        <summary eId="sum_5"> The joint committee adjourned at 1.07 p.m until 11 a.m. on Tuesday, 25 November 2025.</summary>
      </debateSection>
    </debateBody>
  </debate>
</akomaNtoso>
